{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7b7f4dc",
   "metadata": {
    "_uuid": "97b92845b85f289ba795c8c8f7117526abe073d0",
    "papermill": {
     "duration": 0.012435,
     "end_time": "2023-06-25T17:14:16.810937",
     "exception": false,
     "start_time": "2023-06-25T17:14:16.798502",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## IMPORTS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aee53350",
   "metadata": {
    "_uuid": "abb7e3c30b8a412a50c6b451c49939e3cf4bc11b",
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:16.835862Z",
     "iopub.status.busy": "2023-06-25T17:14:16.835074Z",
     "iopub.status.idle": "2023-06-25T17:14:29.278745Z",
     "shell.execute_reply": "2023-06-25T17:14:29.277784Z"
    },
    "papermill": {
     "duration": 12.458972,
     "end_time": "2023-06-25T17:14:29.281252",
     "exception": false,
     "start_time": "2023-06-25T17:14:16.822280",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n",
      "  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n",
      "/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\n",
      "caused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n",
      "  warnings.warn(f\"file system plugins are not loaded: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import copy\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import re\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "#import spacy\n",
    "from tqdm import tqdm_notebook, tnrange\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "tqdm.pandas(desc='Progress')\n",
    "from collections import Counter\n",
    "\n",
    "from nltk import word_tokenize\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "from sklearn.metrics import f1_score\n",
    "import os \n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "\n",
    "# cross validation and metrics\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import f1_score\n",
    "from torch.optim.optimizer import Optimizer\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from multiprocessing import  Pool\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828a3bf4",
   "metadata": {
    "_uuid": "9a4ff5590a6f152dc1bec5aeca79aef10218f7de",
    "papermill": {
     "duration": 0.011005,
     "end_time": "2023-06-25T17:14:29.303847",
     "exception": false,
     "start_time": "2023-06-25T17:14:29.292842",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Basic Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "640ef578",
   "metadata": {
    "_uuid": "deee49df5ca1c4413f71677939e26aa1ff784e44",
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:29.328393Z",
     "iopub.status.busy": "2023-06-25T17:14:29.327708Z",
     "iopub.status.idle": "2023-06-25T17:14:29.333284Z",
     "shell.execute_reply": "2023-06-25T17:14:29.332318Z"
    },
    "papermill": {
     "duration": 0.020116,
     "end_time": "2023-06-25T17:14:29.335273",
     "exception": false,
     "start_time": "2023-06-25T17:14:29.315157",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "embed_size = 300 # how big is each word vector\n",
    "max_features = 120000 # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = 750 # max number of words in a question to use\n",
    "batch_size = 512 # how many samples to process at once\n",
    "n_epochs = 5 # how many times to iterate over all samples\n",
    "n_splits = 5 # Number of K-fold Splits\n",
    "SEED = 10\n",
    "debug = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b67cd9d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:29.359528Z",
     "iopub.status.busy": "2023-06-25T17:14:29.358712Z",
     "iopub.status.idle": "2023-06-25T17:14:31.273314Z",
     "shell.execute_reply": "2023-06-25T17:14:31.272329Z"
    },
    "papermill": {
     "duration": 1.929311,
     "end_time": "2023-06-25T17:14:31.275824",
     "exception": false,
     "start_time": "2023-06-25T17:14:29.346513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data1 = pd.read_csv(\"../input/kuc-hackathon-winter-2018/drugsComTrain_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87a896cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:31.302671Z",
     "iopub.status.busy": "2023-06-25T17:14:31.300785Z",
     "iopub.status.idle": "2023-06-25T17:14:31.838992Z",
     "shell.execute_reply": "2023-06-25T17:14:31.837974Z"
    },
    "papermill": {
     "duration": 0.55324,
     "end_time": "2023-06-25T17:14:31.841272",
     "exception": false,
     "start_time": "2023-06-25T17:14:31.288032",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data2 = pd.read_csv(\"../input/kuc-hackathon-winter-2018/drugsComTest_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "87004b47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:31.865613Z",
     "iopub.status.busy": "2023-06-25T17:14:31.865270Z",
     "iopub.status.idle": "2023-06-25T17:14:31.951309Z",
     "shell.execute_reply": "2023-06-25T17:14:31.950226Z"
    },
    "papermill": {
     "duration": 0.100893,
     "end_time": "2023-06-25T17:14:31.953721",
     "exception": false,
     "start_time": "2023-06-25T17:14:31.852828",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.concat([data1,data2])[['review','condition','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "19230330",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:31.978288Z",
     "iopub.status.busy": "2023-06-25T17:14:31.977955Z",
     "iopub.status.idle": "2023-06-25T17:14:31.992032Z",
     "shell.execute_reply": "2023-06-25T17:14:31.991010Z"
    },
    "papermill": {
     "duration": 0.029531,
     "end_time": "2023-06-25T17:14:31.994636",
     "exception": false,
     "start_time": "2023-06-25T17:14:31.965105",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>condition</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  \"It has no side effect, I take it in combinati...   \n",
       "1  \"My son is halfway through his fourth week of ...   \n",
       "2  \"I used to take another oral contraceptive, wh...   \n",
       "3  \"This is my first time using any form of birth...   \n",
       "4  \"Suboxone has completely turned my life around...   \n",
       "\n",
       "                      condition  rating  \n",
       "0  Left Ventricular Dysfunction       9  \n",
       "1                          ADHD       8  \n",
       "2                 Birth Control       5  \n",
       "3                 Birth Control       8  \n",
       "4             Opiate Dependence       9  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842afa03",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:32.019214Z",
     "iopub.status.busy": "2023-06-25T17:14:32.018901Z",
     "iopub.status.idle": "2023-06-25T17:14:32.065139Z",
     "shell.execute_reply": "2023-06-25T17:14:32.064222Z"
    },
    "papermill": {
     "duration": 0.061162,
     "end_time": "2023-06-25T17:14:32.067319",
     "exception": false,
     "start_time": "2023-06-25T17:14:32.006157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove NULL Values from data\n",
    "data = data[pd.notnull(data['review'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a7c95f",
   "metadata": {
    "papermill": {
     "duration": 0.011299,
     "end_time": "2023-06-25T17:14:32.090234",
     "exception": false,
     "start_time": "2023-06-25T17:14:32.078935",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Finding the maxlen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d41a698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:32.114778Z",
     "iopub.status.busy": "2023-06-25T17:14:32.114424Z",
     "iopub.status.idle": "2023-06-25T17:14:32.285375Z",
     "shell.execute_reply": "2023-06-25T17:14:32.284354Z"
    },
    "papermill": {
     "duration": 0.186066,
     "end_time": "2023-06-25T17:14:32.287850",
     "exception": false,
     "start_time": "2023-06-25T17:14:32.101784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['len'] = data['review'].apply(lambda s : len(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d264f99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:32.313015Z",
     "iopub.status.busy": "2023-06-25T17:14:32.312648Z",
     "iopub.status.idle": "2023-06-25T17:14:32.781744Z",
     "shell.execute_reply": "2023-06-25T17:14:32.780806Z"
    },
    "papermill": {
     "duration": 0.484011,
     "end_time": "2023-06-25T17:14:32.783816",
     "exception": false,
     "start_time": "2023-06-25T17:14:32.299805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='Frequency'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data['len'].plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa4ef962",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:32.810990Z",
     "iopub.status.busy": "2023-06-25T17:14:32.809120Z",
     "iopub.status.idle": "2023-06-25T17:14:32.823800Z",
     "shell.execute_reply": "2023-06-25T17:14:32.822960Z"
    },
    "papermill": {
     "duration": 0.030102,
     "end_time": "2023-06-25T17:14:32.825837",
     "exception": false,
     "start_time": "2023-06-25T17:14:32.795735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "758.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.len.quantile(0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbcb58f",
   "metadata": {
    "papermill": {
     "duration": 0.011878,
     "end_time": "2023-06-25T17:14:32.850732",
     "exception": false,
     "start_time": "2023-06-25T17:14:32.838854",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Preprocessing Y Column\n",
    "We are only going to be classifying conditions for which the count of reviews are more than 3000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b086fadf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:32.876741Z",
     "iopub.status.busy": "2023-06-25T17:14:32.875821Z",
     "iopub.status.idle": "2023-06-25T17:14:33.007281Z",
     "shell.execute_reply": "2023-06-25T17:14:33.006383Z"
    },
    "papermill": {
     "duration": 0.14685,
     "end_time": "2023-06-25T17:14:33.009487",
     "exception": false,
     "start_time": "2023-06-25T17:14:32.862637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>Birth Control</td>\n",
       "      <td>38436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Depression</td>\n",
       "      <td>12164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>613</th>\n",
       "      <td>Pain</td>\n",
       "      <td>8245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Anxiety</td>\n",
       "      <td>7812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Acne</td>\n",
       "      <td>7435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         condition  review\n",
       "175  Birth Control   38436\n",
       "273     Depression   12164\n",
       "613           Pain    8245\n",
       "133        Anxiety    7812\n",
       "87            Acne    7435"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_df = data[['condition','review']].groupby('condition').aggregate({'review':'count'}).reset_index().sort_values('review',ascending=False)\n",
    "count_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00d7ab9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:33.035763Z",
     "iopub.status.busy": "2023-06-25T17:14:33.035435Z",
     "iopub.status.idle": "2023-06-25T17:14:33.041242Z",
     "shell.execute_reply": "2023-06-25T17:14:33.040369Z"
    },
    "papermill": {
     "duration": 0.021618,
     "end_time": "2023-06-25T17:14:33.043347",
     "exception": false,
     "start_time": "2023-06-25T17:14:33.021729",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_conditions = count_df[count_df['review']>3000]['condition'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "858c14c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:33.069467Z",
     "iopub.status.busy": "2023-06-25T17:14:33.069118Z",
     "iopub.status.idle": "2023-06-25T17:14:35.226629Z",
     "shell.execute_reply": "2023-06-25T17:14:35.225687Z"
    },
    "papermill": {
     "duration": 2.174066,
     "end_time": "2023-06-25T17:14:35.229631",
     "exception": false,
     "start_time": "2023-06-25T17:14:33.055565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def condition_parser(x):\n",
    "    if x in target_conditions:\n",
    "        return x\n",
    "    else:\n",
    "        return \"OTHER\"\n",
    "    \n",
    "data['condition'] = data['condition'].apply(lambda x: condition_parser(x))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fc8c19d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:35.266483Z",
     "iopub.status.busy": "2023-06-25T17:14:35.265951Z",
     "iopub.status.idle": "2023-06-25T17:14:35.341519Z",
     "shell.execute_reply": "2023-06-25T17:14:35.340474Z"
    },
    "papermill": {
     "duration": 0.09703,
     "end_time": "2023-06-25T17:14:35.344731",
     "exception": false,
     "start_time": "2023-06-25T17:14:35.247701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = data[data['condition']!='OTHER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7180d371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:35.385477Z",
     "iopub.status.busy": "2023-06-25T17:14:35.384940Z",
     "iopub.status.idle": "2023-06-25T17:14:36.104651Z",
     "shell.execute_reply": "2023-06-25T17:14:36.103663Z"
    },
    "papermill": {
     "duration": 0.741529,
     "end_time": "2023-06-25T17:14:36.107283",
     "exception": false,
     "start_time": "2023-06-25T17:14:35.365754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1781e10c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:36.133792Z",
     "iopub.status.busy": "2023-06-25T17:14:36.133275Z",
     "iopub.status.idle": "2023-06-25T17:14:37.437478Z",
     "shell.execute_reply": "2023-06-25T17:14:37.436579Z"
    },
    "papermill": {
     "duration": 1.319662,
     "end_time": "2023-06-25T17:14:37.439530",
     "exception": false,
     "start_time": "2023-06-25T17:14:36.119868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.20.0.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>                            <div id=\"82b3a3d1-7bca-46a6-b8fa-10e9e0850486\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"82b3a3d1-7bca-46a6-b8fa-10e9e0850486\")) {                    Plotly.newPlot(                        \"82b3a3d1-7bca-46a6-b8fa-10e9e0850486\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"condition=%{x}<br>review=%{y}<extra></extra>\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"Birth Control\",\"Depression\",\"Pain\",\"Anxiety\",\"Acne\",\"Bipolar Disorde\",\"Insomnia\",\"Weight Loss\",\"Obesity\",\"ADHD\",\"Diabetes, Type 2\",\"Emergency Contraception\",\"High Blood Pressure\",\"Vaginal Yeast Infection\"],\"xaxis\":\"x\",\"y\":[38436,12164,8245,7812,7435,5604,4904,4857,4757,4509,3362,3290,3104,3085],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"condition\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"review\"}},\"legend\":{\"tracegroupgap\":0},\"margin\":{\"t\":60},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('82b3a3d1-7bca-46a6-b8fa-10e9e0850486');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "px.bar(count_df[count_df['review']>3000],x='condition',y='review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52a5bb54",
   "metadata": {
    "_uuid": "abeab4c80d6829cf2eae706bfa7929e2871af81f",
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:37.466115Z",
     "iopub.status.busy": "2023-06-25T17:14:37.465791Z",
     "iopub.status.idle": "2023-06-25T17:14:37.471939Z",
     "shell.execute_reply": "2023-06-25T17:14:37.470954Z"
    },
    "papermill": {
     "duration": 0.02178,
     "end_time": "2023-06-25T17:14:37.474087",
     "exception": false,
     "start_time": "2023-06-25T17:14:37.452307",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(x):\n",
    "    pattern = r'[^a-zA-z0-9\\s]'\n",
    "    text = re.sub(pattern, '', x)\n",
    "    return x\n",
    "\n",
    "def clean_numbers(x):\n",
    "    if bool(re.search(r'\\d', x)):\n",
    "        x = re.sub('[0-9]{5,}', '#####', x)\n",
    "        x = re.sub('[0-9]{4}', '####', x)\n",
    "        x = re.sub('[0-9]{3}', '###', x)\n",
    "        x = re.sub('[0-9]{2}', '##', x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43942222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:37.500886Z",
     "iopub.status.busy": "2023-06-25T17:14:37.500562Z",
     "iopub.status.idle": "2023-06-25T17:14:37.522582Z",
     "shell.execute_reply": "2023-06-25T17:14:37.521578Z"
    },
    "papermill": {
     "duration": 0.039232,
     "end_time": "2023-06-25T17:14:37.525846",
     "exception": false,
     "start_time": "2023-06-25T17:14:37.486614",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a text with contraction'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contraction_dict = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "def _get_contractions(contraction_dict):\n",
    "    contraction_re = re.compile('(%s)' % '|'.join(contraction_dict.keys()))\n",
    "    return contraction_dict, contraction_re\n",
    "contractions, contractions_re = _get_contractions(contraction_dict)\n",
    "def replace_contractions(text):\n",
    "    def replace(match):\n",
    "        return contractions[match.group(0)]\n",
    "    return contractions_re.sub(replace, text)\n",
    "# Usage\n",
    "replace_contractions(\"this's a text with contraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "878e940c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:14:37.552814Z",
     "iopub.status.busy": "2023-06-25T17:14:37.552476Z",
     "iopub.status.idle": "2023-06-25T17:15:00.584743Z",
     "shell.execute_reply": "2023-06-25T17:15:00.583757Z"
    },
    "papermill": {
     "duration": 23.04841,
     "end_time": "2023-06-25T17:15:00.587211",
     "exception": false,
     "start_time": "2023-06-25T17:14:37.538801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# lower the text\n",
    "data[\"review\"] = data[\"review\"].apply(lambda x: x.lower())\n",
    "\n",
    "# Clean the text\n",
    "data[\"review\"] = data[\"review\"].apply(lambda x: clean_text(x))\n",
    "\n",
    "# Clean numbers\n",
    "data[\"review\"] = data[\"review\"].apply(lambda x: clean_numbers(x))\n",
    "\n",
    "# Clean Contractions\n",
    "data[\"review\"] = data[\"review\"].apply(lambda x: replace_contractions(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34ca5fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:15:00.614523Z",
     "iopub.status.busy": "2023-06-25T17:15:00.614158Z",
     "iopub.status.idle": "2023-06-25T17:15:00.631421Z",
     "shell.execute_reply": "2023-06-25T17:15:00.630580Z"
    },
    "papermill": {
     "duration": 0.033151,
     "end_time": "2023-06-25T17:15:00.633423",
     "exception": false,
     "start_time": "2023-06-25T17:15:00.600272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ADHD', 'Birth Control', 'Emergency Contraception',\n",
       "       'Bipolar Disorde', 'Depression', 'Obesity', 'Insomnia',\n",
       "       'Vaginal Yeast Infection', 'Pain', 'Diabetes, Type 2', 'Anxiety',\n",
       "       'Acne', 'High Blood Pressure', 'Weight Loss'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['condition'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7855349",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:15:00.661039Z",
     "iopub.status.busy": "2023-06-25T17:15:00.660164Z",
     "iopub.status.idle": "2023-06-25T17:15:00.740303Z",
     "shell.execute_reply": "2023-06-25T17:15:00.739338Z"
    },
    "papermill": {
     "duration": 0.096393,
     "end_time": "2023-06-25T17:15:00.742691",
     "exception": false,
     "start_time": "2023-06-25T17:15:00.646298",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data['sentiment'] = data[\"rating\"].apply(lambda x: 1 if x > 5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3ca8e982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:15:00.770087Z",
     "iopub.status.busy": "2023-06-25T17:15:00.769747Z",
     "iopub.status.idle": "2023-06-25T17:15:00.799036Z",
     "shell.execute_reply": "2023-06-25T17:15:00.798097Z"
    },
    "papermill": {
     "duration": 0.045548,
     "end_time": "2023-06-25T17:15:00.801331",
     "exception": false,
     "start_time": "2023-06-25T17:15:00.755783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_train, df_test = train_test_split(data, test_size = 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d7649dd3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:15:00.828719Z",
     "iopub.status.busy": "2023-06-25T17:15:00.828359Z",
     "iopub.status.idle": "2023-06-25T17:15:00.832931Z",
     "shell.execute_reply": "2023-06-25T17:15:00.831985Z"
    },
    "papermill": {
     "duration": 0.020887,
     "end_time": "2023-06-25T17:15:00.835482",
     "exception": false,
     "start_time": "2023-06-25T17:15:00.814595",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_X = df_train['review']\n",
    "test_X = df_test['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5fc1369",
   "metadata": {
    "_uuid": "63cb21525251b060aeb309e7be4b48772f8720f5",
    "execution": {
     "iopub.execute_input": "2023-06-25T17:15:00.863074Z",
     "iopub.status.busy": "2023-06-25T17:15:00.862133Z",
     "iopub.status.idle": "2023-06-25T17:15:00.867982Z",
     "shell.execute_reply": "2023-06-25T17:15:00.867012Z"
    },
    "papermill": {
     "duration": 0.021687,
     "end_time": "2023-06-25T17:15:00.870006",
     "exception": false,
     "start_time": "2023-06-25T17:15:00.848319",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (83673,)\n",
      "Test shape :  (27891,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Train shape : \",train_X.shape)\n",
    "print(\"Test shape : \",test_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5e0a908f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:15:00.897618Z",
     "iopub.status.busy": "2023-06-25T17:15:00.896795Z",
     "iopub.status.idle": "2023-06-25T17:15:16.040849Z",
     "shell.execute_reply": "2023-06-25T17:15:16.039858Z"
    },
    "papermill": {
     "duration": 15.160781,
     "end_time": "2023-06-25T17:15:16.043521",
     "exception": false,
     "start_time": "2023-06-25T17:15:00.882740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(train_X))\n",
    "train_X = tokenizer.texts_to_sequences(train_X)\n",
    "test_X = tokenizer.texts_to_sequences(test_X)\n",
    "\n",
    "## Pad the sentences \n",
    "train_X = pad_sequences(train_X, maxlen=maxlen)\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a52bea2",
   "metadata": {
    "_uuid": "e5c51a8329d569d13b9f0369ebb98ca8e2e55440",
    "papermill": {
     "duration": 0.0128,
     "end_time": "2023-06-25T17:15:16.069522",
     "exception": false,
     "start_time": "2023-06-25T17:15:16.056722",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Load Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e6d8b4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:15:16.096979Z",
     "iopub.status.busy": "2023-06-25T17:15:16.096626Z",
     "iopub.status.idle": "2023-06-25T17:15:16.106255Z",
     "shell.execute_reply": "2023-06-25T17:15:16.105411Z"
    },
    "papermill": {
     "duration": 0.025738,
     "end_time": "2023-06-25T17:15:16.108259",
     "exception": false,
     "start_time": "2023-06-25T17:15:16.082521",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## FUNCTIONS TAKEN FROM https://www.kaggle.com/gmhost/gru-capsule\n",
    "\n",
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '../input/glove840b300dtxt/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')[:300]\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "    \n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.005838499,0.48782197\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    nb_words = min(max_features, len(word_index)+1)\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: \n",
    "            embedding_matrix[i] = embedding_vector\n",
    "        else:\n",
    "            embedding_vector = embeddings_index.get(word.capitalize())\n",
    "            if embedding_vector is not None: \n",
    "                embedding_matrix[i] = embedding_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c37a2429",
   "metadata": {
    "_uuid": "6a5f4502324d369ff6faa3692accee4f8a233005",
    "execution": {
     "iopub.execute_input": "2023-06-25T17:15:16.136330Z",
     "iopub.status.busy": "2023-06-25T17:15:16.135377Z",
     "iopub.status.idle": "2023-06-25T17:18:31.767428Z",
     "shell.execute_reply": "2023-06-25T17:18:31.766451Z"
    },
    "papermill": {
     "duration": 195.64903,
     "end_time": "2023-06-25T17:18:31.770134",
     "exception": false,
     "start_time": "2023-06-25T17:15:16.121104",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3508: FutureWarning:\n",
      "\n",
      "arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# missing entries in the embedding are set using np.random.normal so we have to seed here too\n",
    "\n",
    "if debug:\n",
    "    embedding_matrix = np.random.randn(120000,300)\n",
    "else:\n",
    "    embedding_matrix = load_glove(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60786b99",
   "metadata": {
    "_uuid": "aa6a41607b804d76a2ddc530c912b5673bcd2423",
    "execution": {
     "iopub.execute_input": "2023-06-25T17:18:31.799918Z",
     "iopub.status.busy": "2023-06-25T17:18:31.799584Z",
     "iopub.status.idle": "2023-06-25T17:18:31.805438Z",
     "shell.execute_reply": "2023-06-25T17:18:31.804571Z"
    },
    "papermill": {
     "duration": 0.02398,
     "end_time": "2023-06-25T17:18:31.807433",
     "exception": false,
     "start_time": "2023-06-25T17:18:31.783453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30981, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(embedding_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced8e18",
   "metadata": {
    "_uuid": "0a78496e4d88d8fb351cdf26d02f1554821ed445",
    "papermill": {
     "duration": 0.01305,
     "end_time": "2023-06-25T17:18:31.834067",
     "exception": false,
     "start_time": "2023-06-25T17:18:31.821017",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Pytorch Model - TextCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c4554c9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:18:31.862694Z",
     "iopub.status.busy": "2023-06-25T17:18:31.862332Z",
     "iopub.status.idle": "2023-06-25T17:18:31.877991Z",
     "shell.execute_reply": "2023-06-25T17:18:31.877132Z"
    },
    "papermill": {
     "duration": 0.032335,
     "end_time": "2023-06-25T17:18:31.880026",
     "exception": false,
     "start_time": "2023-06-25T17:18:31.847691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class RegressionTrain(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, model,init_weight):\n",
    "        super(RegressionTrain, self).__init__()\n",
    "\n",
    "        self.model = model\n",
    "        self.weights = torch.nn.Parameter(torch.from_numpy(init_weight).float())\n",
    "        self.ce_loss = nn.CrossEntropyLoss()\n",
    "        self.mse_loss = nn.MSELoss()\n",
    "\n",
    "    def forward(self, x, ts):\n",
    "        n_tasks = 2\n",
    "        logit = self.model(x)\n",
    "        task_loss = []\n",
    "\n",
    "        task_loss.append(self.ce_loss(logit[0], ts[:, 0]))\n",
    "        task_loss.append(self.ce_loss(logit[1], ts[:, 1]))\n",
    "\n",
    "        task_loss = torch.stack(task_loss)\n",
    "\n",
    "        return task_loss\n",
    "\n",
    "\n",
    "class RegressionModel(torch.nn.Module):\n",
    "    def __init__(self, n_tasks):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        filter_sizes = [1,2,3,5]\n",
    "        num_filters = 36\n",
    "        self.n_tasks = n_tasks\n",
    "        self.embedding = nn.Embedding(max_features, embed_size)\n",
    "        self.embedding.weight = nn.Parameter(torch.tensor(embedding_matrix, dtype=torch.float32))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        self.convs1 = nn.ModuleList([nn.Conv2d(1, num_filters, (K, embed_size)) for K in filter_sizes])\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        setattr(self, 'task_{}'.format(0), nn.Linear(len(filter_sizes)*num_filters, data.sentiment.nunique())) #2\n",
    "        setattr(self, 'task_{}'.format(1), nn.Linear(len(filter_sizes)*num_filters, data.condition.nunique())) #num_classes\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  \n",
    "        x = x.unsqueeze(1)  \n",
    "        x = [F.relu(conv(x)).squeeze(3) for conv in self.convs1] \n",
    "        x = [F.max_pool1d(i, i.size(2)).squeeze(2) for i in x]  \n",
    "        x = torch.cat(x, 1)\n",
    "        x = self.dropout(x)  \n",
    "        \n",
    "        outs = []\n",
    "        for i in range(self.n_tasks):\n",
    "            layer = getattr(self, 'task_{}'.format(i))\n",
    "            outs.append(layer(x))\n",
    "\n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b80a6414",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:18:31.907777Z",
     "iopub.status.busy": "2023-06-25T17:18:31.907384Z",
     "iopub.status.idle": "2023-06-25T17:18:31.917521Z",
     "shell.execute_reply": "2023-06-25T17:18:31.916652Z"
    },
    "papermill": {
     "duration": 0.026367,
     "end_time": "2023-06-25T17:18:31.919579",
     "exception": false,
     "start_time": "2023-06-25T17:18:31.893212",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_make(df_train, df_test):\n",
    "    le = LabelEncoder()\n",
    "    batch_size = 256\n",
    "    \n",
    "\n",
    "    train_label2 = le.fit_transform(df_train['condition'].values)[:, np.newaxis]\n",
    "    # train_label2 = tf.keras.utils.to_categorical(train_label2, num_classes=num_classes)\n",
    "    # val_label2 = tf.keras.utils.to_categorical(val_label2, num_classes=num_classes)\n",
    "    test_label2 = le.transform(df_test['condition'].values)[:, np.newaxis]\n",
    "    #test_label2 = tf.keras.utils.to_categorical(test_label2, num_classes=num_classes)\n",
    "\n",
    "\n",
    "    # train_label1 = tf.keras.utils.to_categorical(df_train['sentiment'].values[:, np.newaxis], num_classes=2)\n",
    "    # val_label1 = tf.keras.utils.to_categorical(df_val['sentiment'].values[:, np.newaxis], num_classes=2)\n",
    "    # test_label1 = tf.keras.utils.to_categorical(df_test['sentiment'].values[:, np.newaxis], num_classes=2)\n",
    "\n",
    "    train_label1 = df_train['sentiment'].values[:, np.newaxis]\n",
    "    test_label1 = df_test['sentiment'].values[:, np.newaxis]\n",
    "\n",
    "    train_Y = np.concatenate((train_label1, train_label2), axis=1)\n",
    "    test_Y = np.concatenate((test_label1, test_label2), axis=1)\n",
    "\n",
    "    x_train = torch.from_numpy(train_X).long().cuda()\n",
    "    y_train = torch.from_numpy(train_Y).long().cuda()\n",
    "    x_test = torch.from_numpy(test_X).long().cuda()\n",
    "    y_test = torch.from_numpy(test_Y).long().cuda()\n",
    "\n",
    "    # Create Torch datasets\n",
    "    train = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "    test = torch.utils.data.TensorDataset(x_test, y_test)\n",
    "    # Create Data Loaders\n",
    "    train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "   \n",
    "    test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137f4409",
   "metadata": {
    "_uuid": "0da30e2afce23b753796f3045b44ce91a07e4303",
    "papermill": {
     "duration": 0.013144,
     "end_time": "2023-06-25T17:18:31.946081",
     "exception": false,
     "start_time": "2023-06-25T17:18:31.932937",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Train TextCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8399fff7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:18:31.976957Z",
     "iopub.status.busy": "2023-06-25T17:18:31.976616Z",
     "iopub.status.idle": "2023-06-25T17:18:32.014365Z",
     "shell.execute_reply": "2023-06-25T17:18:32.013336Z"
    },
    "papermill": {
     "duration": 0.056775,
     "end_time": "2023-06-25T17:18:32.016393",
     "exception": false,
     "start_time": "2023-06-25T17:18:31.959618",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This code is from\n",
    "# Multi-Task Learning as Multi-Objective Optimization\n",
    "# Ozan Sener, Vladlen Koltun\n",
    "# Neural Information Processing Systems (NeurIPS) 2018\n",
    "# https://github.com/intel-isl/MultiObjectiveOptimization\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class MinNormSolver:\n",
    "    MAX_ITER = 250\n",
    "    STOP_CRIT = 1e-5\n",
    "\n",
    "    def _min_norm_element_from2(v1v1, v1v2, v2v2):\n",
    "        \"\"\"\n",
    "        Analytical solution for min_{c} |cx_1 + (1-c)x_2|_2^2\n",
    "        d is the distance (objective) optimzed\n",
    "        v1v1 = <x1,x1>\n",
    "        v1v2 = <x1,x2>\n",
    "        v2v2 = <x2,x2>\n",
    "        \"\"\"\n",
    "        if v1v2 >= v1v1:\n",
    "            # Case: Fig 1, third column\n",
    "            gamma = 0.999\n",
    "            cost = v1v1\n",
    "            return gamma, cost\n",
    "        if v1v2 >= v2v2:\n",
    "            # Case: Fig 1, first column\n",
    "            gamma = 0.001\n",
    "            cost = v2v2\n",
    "            return gamma, cost\n",
    "        # Case: Fig 1, second column\n",
    "        gamma = -1.0 * ( (v1v2 - v2v2) / (v1v1+v2v2 - 2*v1v2) )\n",
    "        cost = v2v2 + gamma*(v1v2 - v2v2)\n",
    "        return gamma, cost\n",
    "\n",
    "    def _min_norm_2d(vecs, dps):\n",
    "        \"\"\"\n",
    "        Find the minimum norm solution as combination of two points\n",
    "        This is correct only in 2D\n",
    "        ie. min_c |\\sum c_i x_i|_2^2 st. \\sum c_i = 1 , 1 >= c_1 >= 0 for all i, c_i + c_j = 1.0 for some i, j\n",
    "        \"\"\"\n",
    "        dmin = 1e8\n",
    "        for i in range(len(vecs)):\n",
    "            for j in range(i+1,len(vecs)):\n",
    "                if (i,j) not in dps:\n",
    "                    dps[(i, j)] = 0.0\n",
    "                    for k in range(len(vecs[i])):\n",
    "                        dps[(i,j)] += torch.dot(vecs[i][k], vecs[j][k]).item()#torch.dot(vecs[i][k], vecs[j][k]).data[0]\n",
    "                    dps[(j, i)] = dps[(i, j)]\n",
    "                if (i,i) not in dps:\n",
    "                    dps[(i, i)] = 0.0\n",
    "                    for k in range(len(vecs[i])):\n",
    "                        dps[(i,i)] += torch.dot(vecs[i][k], vecs[i][k]).item()#torch.dot(vecs[i][k], vecs[i][k]).data[0]\n",
    "                if (j,j) not in dps:\n",
    "                    dps[(j, j)] = 0.0\n",
    "                    for k in range(len(vecs[i])):\n",
    "                        dps[(j, j)] += torch.dot(vecs[j][k], vecs[j][k]).item()#torch.dot(vecs[j][k], vecs[j][k]).data[0]\n",
    "                c,d = MinNormSolver._min_norm_element_from2(dps[(i,i)], dps[(i,j)], dps[(j,j)])\n",
    "                if d < dmin:\n",
    "                    dmin = d\n",
    "                    sol = [(i,j),c,d]\n",
    "        return sol, dps\n",
    "\n",
    "    def _projection2simplex(y):\n",
    "        \"\"\"\n",
    "        Given y, it solves argmin_z |y-z|_2 st \\sum z = 1 , 1 >= z_i >= 0 for all i\n",
    "        \"\"\"\n",
    "        m = len(y)\n",
    "        sorted_y = np.flip(np.sort(y), axis=0)\n",
    "        tmpsum = 0.0\n",
    "        tmax_f = (np.sum(y) - 1.0)/m\n",
    "        for i in range(m-1):\n",
    "            tmpsum+= sorted_y[i]\n",
    "            tmax = (tmpsum - 1)/ (i+1.0)\n",
    "            if tmax > sorted_y[i+1]:\n",
    "                tmax_f = tmax\n",
    "                break\n",
    "        return np.maximum(y - tmax_f, np.zeros(y.shape))\n",
    "\n",
    "    def _next_point(cur_val, grad, n):\n",
    "        proj_grad = grad - ( np.sum(grad) / n )\n",
    "        tm1 = -1.0*cur_val[proj_grad<0]/proj_grad[proj_grad<0]\n",
    "        tm2 = (1.0 - cur_val[proj_grad>0])/(proj_grad[proj_grad>0])\n",
    "\n",
    "        skippers = np.sum(tm1<1e-7) + np.sum(tm2<1e-7)\n",
    "        t = 1\n",
    "        if len(tm1[tm1>1e-7]) > 0:\n",
    "            t = np.min(tm1[tm1>1e-7])\n",
    "        if len(tm2[tm2>1e-7]) > 0:\n",
    "            t = min(t, np.min(tm2[tm2>1e-7]))\n",
    "\n",
    "        next_point = proj_grad*t + cur_val\n",
    "        next_point = MinNormSolver._projection2simplex(next_point)\n",
    "        return next_point\n",
    "\n",
    "    def find_min_norm_element(vecs):\n",
    "        \"\"\"\n",
    "        Given a list of vectors (vecs), this method finds the minimum norm element in the convex hull\n",
    "        as min |u|_2 st. u = \\sum c_i vecs[i] and \\sum c_i = 1.\n",
    "        It is quite geometric, and the main idea is the fact that if d_{ij} = min |u|_2 st u = c x_i + (1-c) x_j; the solution lies in (0, d_{i,j})\n",
    "        Hence, we find the best 2-task solution, and then run the projected gradient descent until convergence\n",
    "        \"\"\"\n",
    "        # Solution lying at the combination of two points\n",
    "        dps = {}\n",
    "        init_sol, dps = MinNormSolver._min_norm_2d(vecs, dps)\n",
    "\n",
    "        n=len(vecs)\n",
    "        sol_vec = np.zeros(n)\n",
    "        sol_vec[init_sol[0][0]] = init_sol[1]\n",
    "        sol_vec[init_sol[0][1]] = 1 - init_sol[1]\n",
    "\n",
    "        if n < 3:\n",
    "            # This is optimal for n=2, so return the solution\n",
    "            return sol_vec , init_sol[2]\n",
    "\n",
    "        iter_count = 0\n",
    "\n",
    "        grad_mat = np.zeros((n,n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                grad_mat[i,j] = dps[(i, j)]\n",
    "\n",
    "\n",
    "        while iter_count < MinNormSolver.MAX_ITER:\n",
    "            grad_dir = -1.0*np.dot(grad_mat, sol_vec)\n",
    "            new_point = MinNormSolver._next_point(sol_vec, grad_dir, n)\n",
    "            # Re-compute the inner products for line search\n",
    "            v1v1 = 0.0\n",
    "            v1v2 = 0.0\n",
    "            v2v2 = 0.0\n",
    "            for i in range(n):\n",
    "                for j in range(n):\n",
    "                    v1v1 += sol_vec[i]*sol_vec[j]*dps[(i,j)]\n",
    "                    v1v2 += sol_vec[i]*new_point[j]*dps[(i,j)]\n",
    "                    v2v2 += new_point[i]*new_point[j]*dps[(i,j)]\n",
    "            nc, nd = MinNormSolver._min_norm_element_from2(v1v1, v1v2, v2v2)\n",
    "            new_sol_vec = nc*sol_vec + (1-nc)*new_point\n",
    "            change = new_sol_vec - sol_vec\n",
    "            if np.sum(np.abs(change)) < MinNormSolver.STOP_CRIT:\n",
    "                return sol_vec, nd\n",
    "            sol_vec = new_sol_vec\n",
    "\n",
    "    def find_min_norm_element_FW(vecs):\n",
    "        \"\"\"\n",
    "        Given a list of vectors (vecs), this method finds the minimum norm element in the convex hull\n",
    "        as min |u|_2 st. u = \\sum c_i vecs[i] and \\sum c_i = 1.\n",
    "        It is quite geometric, and the main idea is the fact that if d_{ij} = min |u|_2 st u = c x_i + (1-c) x_j; the solution lies in (0, d_{i,j})\n",
    "        Hence, we find the best 2-task solution, and then run the Frank Wolfe until convergence\n",
    "        \"\"\"\n",
    "        # Solution lying at the combination of two points\n",
    "        dps = {}\n",
    "        init_sol, dps = MinNormSolver._min_norm_2d(vecs, dps)\n",
    "\n",
    "        n=len(vecs)\n",
    "        sol_vec = np.zeros(n)\n",
    "        sol_vec[init_sol[0][0]] = init_sol[1]\n",
    "        sol_vec[init_sol[0][1]] = 1 - init_sol[1]\n",
    "\n",
    "        if n < 3:\n",
    "            # This is optimal for n=2, so return the solution\n",
    "            return sol_vec , init_sol[2]\n",
    "\n",
    "        iter_count = 0\n",
    "\n",
    "        grad_mat = np.zeros((n,n))\n",
    "        for i in range(n):\n",
    "            for j in range(n):\n",
    "                grad_mat[i,j] = dps[(i, j)]\n",
    "\n",
    "        while iter_count < MinNormSolver.MAX_ITER:\n",
    "            t_iter = np.argmin(np.dot(grad_mat, sol_vec))\n",
    "\n",
    "            v1v1 = np.dot(sol_vec, np.dot(grad_mat, sol_vec))\n",
    "            v1v2 = np.dot(sol_vec, grad_mat[:, t_iter])\n",
    "            v2v2 = grad_mat[t_iter, t_iter]\n",
    "\n",
    "            nc, nd = MinNormSolver._min_norm_element_from2(v1v1, v1v2, v2v2)\n",
    "            new_sol_vec = nc*sol_vec\n",
    "            new_sol_vec[t_iter] += 1 - nc\n",
    "\n",
    "            change = new_sol_vec - sol_vec\n",
    "            if np.sum(np.abs(change)) < MinNormSolver.STOP_CRIT:\n",
    "                return sol_vec, nd\n",
    "            sol_vec = new_sol_vec\n",
    "\n",
    "\n",
    "def gradient_normalizers(grads, losses, normalization_type):\n",
    "    gn = {}\n",
    "    if normalization_type == 'l2':\n",
    "        for t in grads:\n",
    "            gn[t] = np.sqrt(np.sum([gr.pow(2).sum().data[0] for gr in grads[t]]))\n",
    "    elif normalization_type == 'loss':\n",
    "        for t in grads:\n",
    "            gn[t] = losses[t]\n",
    "    elif normalization_type == 'loss+':\n",
    "        for t in grads:\n",
    "            gn[t] = losses[t] * np.sqrt(np.sum([gr.pow(2).sum().data[0] for gr in grads[t]]))\n",
    "    elif normalization_type == 'none':\n",
    "        for t in grads:\n",
    "            gn[t] = 1.0\n",
    "    else:\n",
    "        print('ERROR: Invalid Normalization Type')\n",
    "    return gn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbe436f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:18:32.045600Z",
     "iopub.status.busy": "2023-06-25T17:18:32.044830Z",
     "iopub.status.idle": "2023-06-25T17:18:32.061290Z",
     "shell.execute_reply": "2023-06-25T17:18:32.060443Z"
    },
    "papermill": {
     "duration": 0.033603,
     "end_time": "2023-06-25T17:18:32.063278",
     "exception": false,
     "start_time": "2023-06-25T17:18:32.029675",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_d_paretomtl_init(grads,value,weights,i):\n",
    "    \"\"\"\n",
    "    calculate the gradient direction for ParetoMTL initialization\n",
    "    \"\"\"\n",
    "\n",
    "    flag = False\n",
    "    nobj = value.shape\n",
    "\n",
    "    # check active constraints\n",
    "    current_weight = weights[i]\n",
    "    rest_weights = weights\n",
    "    w = rest_weights - current_weight\n",
    "\n",
    "    gx =  torch.matmul(w,value/torch.norm(value))\n",
    "    idx = gx >  0\n",
    "\n",
    "    # calculate the descent direction\n",
    "    if torch.sum(idx) <= 0:\n",
    "        flag = True\n",
    "        return flag, torch.zeros(nobj)\n",
    "    if torch.sum(idx) == 1:\n",
    "        sol = torch.ones(1).cuda().float()\n",
    "    else:\n",
    "        vec =  torch.matmul(w[idx],grads)\n",
    "        sol, nd = MinNormSolver.find_min_norm_element([[vec[t]] for t in range(len(vec))])\n",
    "\n",
    "\n",
    "    weight0 =  torch.sum(torch.stack([sol[j] * w[idx][j ,0] for j in torch.arange(0, torch.sum(idx))]))\n",
    "    weight1 =  torch.sum(torch.stack([sol[j] * w[idx][j ,1] for j in torch.arange(0, torch.sum(idx))]))\n",
    "    weight = torch.stack([weight0,weight1])\n",
    "\n",
    "\n",
    "    return flag, weight\n",
    "\n",
    "\n",
    "def get_d_paretomtl(grads,value,weights,i):\n",
    "    \"\"\" calculate the gradient direction for ParetoMTL \"\"\"\n",
    "\n",
    "    # check active constraints\n",
    "    current_weight = weights[i]\n",
    "    rest_weights = weights\n",
    "    w = rest_weights - current_weight\n",
    "\n",
    "    gx =  torch.matmul(w,value/torch.norm(value))\n",
    "    idx = gx >  0\n",
    "\n",
    "\n",
    "    # calculate the descent direction\n",
    "    if torch.sum(idx) <= 0:\n",
    "        sol, nd = MinNormSolver.find_min_norm_element([[grads[t]] for t in range(len(grads))])\n",
    "        return torch.tensor(sol).cuda().float()\n",
    "\n",
    "\n",
    "    vec =  torch.cat((grads, torch.matmul(w[idx],grads)))\n",
    "    sol, nd = MinNormSolver.find_min_norm_element([[vec[t]] for t in range(len(vec))])\n",
    "\n",
    "\n",
    "    weight0 =  sol[0] + torch.sum(torch.stack([sol[j] * w[idx][j - 2 ,0] for j in torch.arange(2, 2 + torch.sum(idx))]))\n",
    "    weight1 =  sol[1] + torch.sum(torch.stack([sol[j] * w[idx][j - 2 ,1] for j in torch.arange(2, 2 + torch.sum(idx))]))\n",
    "    weight = torch.stack([weight0,weight1])\n",
    "\n",
    "    return weight\n",
    "\n",
    "\n",
    "def circle_points(r, n):\n",
    "    \"\"\"\n",
    "    generate evenly distributed unit preference vectors for two tasks\n",
    "    \"\"\"\n",
    "    circles = []\n",
    "    for r, n in zip(r, n):\n",
    "        t = np.linspace(0, 0.5 * np.pi, n)\n",
    "        x = r * np.cos(t)\n",
    "        y = r * np.sin(t)\n",
    "        circles.append(np.c_[x, y])\n",
    "    return circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bc9c7db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:18:32.091585Z",
     "iopub.status.busy": "2023-06-25T17:18:32.091223Z",
     "iopub.status.idle": "2023-06-25T17:18:32.440788Z",
     "shell.execute_reply": "2023-06-25T17:18:32.439632Z"
    },
    "papermill": {
     "duration": 0.366596,
     "end_time": "2023-06-25T17:18:32.443062",
     "exception": false,
     "start_time": "2023-06-25T17:18:32.076466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(base_model, niter, npref, init_weight, pref_idx, sigma = 5*1e-1, k = 0.95, Lr = 1e-2):\n",
    "\n",
    "    # generate #npref preference vectors\n",
    "    n_tasks = 2\n",
    "    ref_vec = torch.tensor(circle_points([1], [npref])[0]).cuda().float()\n",
    "\n",
    "    # load dataset\n",
    "    train_loader, test_loader = data_make(df_train, df_test)\n",
    "\n",
    "    print('==>>> total trainning batch number: {}'.format(len(train_loader)))\n",
    "    print('==>>> total testing batch number: {}'.format(len(test_loader)))\n",
    "\n",
    "\n",
    "      # define the base model for ParetoMTL\n",
    "    if base_model == 'lenet':\n",
    "        model = RegressionTrain(RegressionModel(n_tasks), init_weight)\n",
    "    if base_model == 'resnet18':\n",
    "        model = RegressionTrainResNet(MnistResNet(n_tasks), init_weight)\n",
    "\n",
    "    # choose different optimizer for different base model\n",
    "    if base_model == 'lenet':\n",
    "        optimizer = torch.optim.SGD(model.parameters(), lr= Lr, momentum=0.9)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[15,30,45,60,75,90], gamma=0.5)\n",
    "\n",
    "    if base_model == 'resnet18':\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr= Lr)\n",
    "        scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[10,20], gamma=0.1)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    model.model.embedding.requires_grad_(False)\n",
    "   \n",
    "    # store infomation during optimization\n",
    "    weights = []\n",
    "    task_train_losses = []\n",
    "    train_accs = []\n",
    "    task_test_losses = []\n",
    "    test_accs = []\n",
    "    learning_rate = []\n",
    "\n",
    "    # print the current preference vector\n",
    "    print('Preference Vector ({}/{}):'.format(pref_idx + 1, npref))\n",
    "    print(ref_vec[pref_idx].cpu().numpy())\n",
    "    learning_rate.append(Lr)\n",
    "    # run at most 2 epochs to find the initial solution\n",
    "    # stop early once a feasible solution is found\n",
    "    # usually can be found with a few steps\n",
    "    for t in range(2):\n",
    "\n",
    "        model.train()\n",
    "        for (it, batch) in enumerate(train_loader):\n",
    "            X = batch[0]\n",
    "            ts = batch[1]\n",
    "            if torch.cuda.is_available():\n",
    "                X = X.cuda()\n",
    "                ts = ts.cuda()\n",
    "\n",
    "            grads = {}\n",
    "            losses_vec = []\n",
    "\n",
    "\n",
    "            # obtain and store the gradient value\n",
    "            for i in range(n_tasks):\n",
    "                optimizer.zero_grad()\n",
    "                task_loss = model(X, ts)\n",
    "                losses_vec.append(task_loss[i].data)\n",
    "\n",
    "                task_loss[i].backward()\n",
    "\n",
    "                grads[i] = []\n",
    "\n",
    "                # can use scalable method proposed in the MOO-MTL paper for large scale problem\n",
    "                # but we keep use the gradient of all parameters in this experiment\n",
    "                for param in model.parameters():\n",
    "                    if param.grad is not None:\n",
    "                        grads[i].append(Variable(param.grad.data.clone().flatten(), requires_grad=False))\n",
    "\n",
    "\n",
    "\n",
    "            grads_list = [torch.cat(grads[i]) for i in range(len(grads))]\n",
    "            grads = torch.stack(grads_list)\n",
    "\n",
    "            # calculate the weights\n",
    "            losses_vec = torch.stack(losses_vec)\n",
    "            flag, weight_vec = get_d_paretomtl_init(grads,losses_vec,ref_vec,pref_idx)\n",
    "\n",
    "            # early stop once a feasible solution is obtained\n",
    "            if flag == True:\n",
    "                print(\"fealsible solution is obtained.\")\n",
    "                break\n",
    "\n",
    "            # optimization step\n",
    "            optimizer.zero_grad()\n",
    "            for i in range(len(task_loss)):\n",
    "                task_loss = model(X, ts)\n",
    "                if i == 0:\n",
    "                    loss_total = weight_vec[i] * task_loss[i]\n",
    "                else:\n",
    "                    loss_total = loss_total + weight_vec[i] * task_loss[i]\n",
    "\n",
    "            loss_total.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        else:\n",
    "        # continue if no feasible solution is found\n",
    "            continue\n",
    "        # break the loop once a feasible solutions is found\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "    # run niter epochs of ParetoMTL\n",
    "    for t in range(niter):\n",
    "\n",
    "        model.train()\n",
    "        \n",
    "        e = 0\n",
    "        loss_total_full = 0\n",
    "        loss_total_after_full = 0\n",
    "        \n",
    "        for (it, batch) in enumerate(train_loader):\n",
    "\n",
    "            X = batch[0]\n",
    "            ts = batch[1]\n",
    "            if torch.cuda.is_available():\n",
    "                X = X.cuda()\n",
    "                ts = ts.cuda()\n",
    "\n",
    "            # obtain and store the gradient\n",
    "            grads = {}\n",
    "            losses_vec = []\n",
    "\n",
    "            for i in range(n_tasks):\n",
    "                optimizer.zero_grad()\n",
    "                task_loss = model(X, ts)\n",
    "                losses_vec.append(task_loss[i].data)\n",
    "\n",
    "                task_loss[i].backward()\n",
    "\n",
    "                # can use scalable method proposed in the MOO-MTL paper for large scale problem\n",
    "                # but we keep use the gradient of all parameters in this experiment\n",
    "                grads[i] = []\n",
    "                for param in model.parameters():\n",
    "                    if param.grad is not None:\n",
    "                        grads[i].append(Variable(param.grad.data.clone().flatten(), requires_grad=False))\n",
    "\n",
    "\n",
    "\n",
    "            grads_list = [torch.cat(grads[i]) for i in range(len(grads))]\n",
    "            grads = torch.stack(grads_list)\n",
    "\n",
    "            # calculate the weights\n",
    "            losses_vec = torch.stack(losses_vec)\n",
    "            weight_vec = get_d_paretomtl(grads,losses_vec,ref_vec,pref_idx)\n",
    "\n",
    "            normalize_coeff = n_tasks / torch.sum(torch.abs(weight_vec))\n",
    "            weight_vec = weight_vec * normalize_coeff\n",
    "\n",
    "            # optimization step\n",
    "            optimizer.zero_grad()\n",
    "            for i in range(len(task_loss)):\n",
    "                task_loss = model(X, ts)\n",
    "                if i == 0:\n",
    "                    loss_total = weight_vec[i] * task_loss[i]\n",
    "                else:\n",
    "                    loss_total = loss_total + weight_vec[i] * task_loss[i]\n",
    "                    \n",
    "            loss_total_full += loss_total.item()\n",
    "            loss_total.backward()\n",
    "            \n",
    "            for p in model.parameters():\n",
    "                if p.requires_grad is False:\n",
    "                    continue\n",
    "                dp = p.grad\n",
    "                if dp == None:\n",
    "                    continue\n",
    "                p_pre = p.data.clone()\n",
    "                p.data -= Lr*dp\n",
    "                e += torch.matmul(dp.flatten(),(p_pre.data - p.data).flatten())\n",
    "            \n",
    "            #GDA Hyper-param  ==== optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            for i in range(len(task_loss)):\n",
    "                task_loss_after = model(X, ts)\n",
    "                if i == 0:\n",
    "                    loss_total_after = weight_vec[i] * task_loss_after[i]\n",
    "                else:\n",
    "                    loss_total_after = loss_total_after + weight_vec[i] * task_loss_after[i]\n",
    "            loss_total_after_full += loss_total_after.item()\n",
    "            \n",
    "#             print(loss_total_after - loss_total + sigma*e)\n",
    "#             if loss_total_after - loss_total + sigma*e <=0:\n",
    "#                 Lr = Lr\n",
    "#             else:\n",
    "#                 print('Learning rate gets updated')\n",
    "#                 Lr = k*Lr\n",
    "        \n",
    "#         print(loss_total_after_full - loss_total_full)\n",
    "#         print(sigma*e)\n",
    "        if  loss_total_after_full - loss_total_full + sigma*(e) <= 0:\n",
    "            Lr = Lr\n",
    "        else:\n",
    "            print('Learning rate gets updated')\n",
    "            Lr = k*Lr\n",
    "        learning_rate.append(Lr)\n",
    "        # calculate and record performance\n",
    "        if t == 0 or (t + 1) % 2 == 0:\n",
    "\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "\n",
    "                total_train_loss = []\n",
    "                train_acc = []\n",
    "\n",
    "                correct1_train = 0\n",
    "                correct2_train = 0\n",
    "\n",
    "                for (it, batch) in enumerate(train_loader):\n",
    "\n",
    "                    X = batch[0]\n",
    "                    ts = batch[1]\n",
    "                    if torch.cuda.is_available():\n",
    "                        X = X.cuda()\n",
    "                        ts = ts.cuda()\n",
    "\n",
    "                    valid_train_loss = model(X, ts)\n",
    "                    total_train_loss.append(valid_train_loss)\n",
    "                    output1 = model.model(X)[0].max(1, keepdim=True)[1]\n",
    "                    output2 = model.model(X)[1].max(1, keepdim=True)[1]\n",
    "                    correct1_train += output1.eq(ts[:,0].view_as(output1)).sum().item()\n",
    "                    correct2_train += output2.eq(ts[:,1].view_as(output2)).sum().item()\n",
    "\n",
    "\n",
    "                train_acc = np.stack([1.0 * correct1_train / len(train_loader.dataset),1.0 * correct2_train / len(train_loader.dataset)])\n",
    "\n",
    "                total_train_loss = torch.stack(total_train_loss)\n",
    "                average_train_loss = torch.mean(total_train_loss, dim = 0)\n",
    "\n",
    "                total_test_loss = []\n",
    "                test_acc = []\n",
    "\n",
    "                correct1_test = 0\n",
    "                correct2_test = 0\n",
    "\n",
    "                for (it, batch) in enumerate(test_loader):\n",
    "\n",
    "                    X = batch[0]\n",
    "                    ts = batch[1]\n",
    "                    if torch.cuda.is_available():\n",
    "                        X = X.cuda()\n",
    "                        ts = ts.cuda()\n",
    "\n",
    "                    valid_test_loss = model(X, ts)\n",
    "                    total_test_loss.append(valid_test_loss)\n",
    "                    output1 = model.model(X)[0].max(1, keepdim=True)[1]\n",
    "                    output2 = model.model(X)[1].max(1, keepdim=True)[1]\n",
    "                    correct1_test += output1.eq(ts[:,0].view_as(output1)).sum().item()\n",
    "                    correct2_test += output2.eq(ts[:,1].view_as(output2)).sum().item()\n",
    "\n",
    "\n",
    "                test_acc = np.stack([1.0 * correct1_test / len(test_loader.dataset),1.0 * correct2_test / len(test_loader.dataset)])\n",
    "\n",
    "                total_test_loss = torch.stack(total_test_loss)\n",
    "                average_test_loss = torch.mean(total_test_loss, dim = 0)\n",
    "            # record and print\n",
    "            if torch.cuda.is_available():\n",
    "\n",
    "                task_train_losses.append(average_train_loss.data.cpu().numpy())\n",
    "                train_accs.append(train_acc)\n",
    "\n",
    "                task_test_losses.append(average_test_loss.data.cpu().numpy())\n",
    "                test_accs.append(test_acc)\n",
    "                weights.append(weight_vec.cpu().numpy())\n",
    "\n",
    "                print('{}/{}: weights={}, train_loss={}, train_acc={}, test_loss={}, test_acc={}'.format(\n",
    "                        t + 1, niter,  weights[-1], task_train_losses[-1],train_accs[-1], task_test_losses[-1], test_accs[-1]))\n",
    "\n",
    "\n",
    "    torch.save(model.model.state_dict(), '/kaggle/working//%s_niter_%d_npref_%d_prefidx_%d.pickle'%(base_model, niter, npref, pref_idx))\n",
    "\n",
    "    return task_train_losses, train_accs, task_test_losses, test_accs, learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b374971",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:18:32.472336Z",
     "iopub.status.busy": "2023-06-25T17:18:32.471301Z",
     "iopub.status.idle": "2023-06-25T17:18:32.479283Z",
     "shell.execute_reply": "2023-06-25T17:18:32.478380Z"
    },
    "papermill": {
     "duration": 0.024851,
     "end_time": "2023-06-25T17:18:32.481387",
     "exception": false,
     "start_time": "2023-06-25T17:18:32.456536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run(dataset = 'fashion_and_mnist', base_model = 'resnet18', niter = 100, npref = 20):\n",
    "    \"\"\"\n",
    "    run Pareto MTL\n",
    "    \"\"\"\n",
    "\n",
    "    init_weight = np.array([0.5 , 0.5 ])\n",
    "    task_train_losses_pref = []\n",
    "    train_accs_pref = []\n",
    "    task_test_losses_pref = []\n",
    "    test_accs_pref = []\n",
    "    learning_rate_pref = []\n",
    "\n",
    "    for i in range(npref):\n",
    "\n",
    "        pref_idx = i\n",
    "        task_train_losses, train_accs, task_test_losses, test_accs, learning_rate = train(base_model, niter, npref, init_weight, pref_idx)\n",
    "        task_train_losses_pref.append(task_train_losses)\n",
    "        train_accs_pref.append(train_accs)\n",
    "        task_test_losses_pref.append(task_test_losses)\n",
    "        test_accs_pref.append(test_accs)\n",
    "        learning_rate_pref.append(learning_rate)\n",
    "\n",
    "    return  task_train_losses_pref, train_accs_pref, task_test_losses_pref, test_accs_pref, learning_rate_pref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "29261b59",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-25T17:18:32.510037Z",
     "iopub.status.busy": "2023-06-25T17:18:32.509111Z",
     "iopub.status.idle": "2023-06-26T02:40:36.829013Z",
     "shell.execute_reply": "2023-06-26T02:40:36.825313Z"
    },
    "papermill": {
     "duration": 33724.358391,
     "end_time": "2023-06-26T02:40:36.853281",
     "exception": false,
     "start_time": "2023-06-25T17:18:32.494890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total trainning batch number: 327\n",
      "==>>> total testing batch number: 109\n",
      "Preference Vector (1/5):\n",
      "[1. 0.]\n",
      "fealsible solution is obtained.\n",
      "1/50: weights=[0.00512262 1.9948773 ], train_loss=[7.7462263 1.4331763], train_acc=[0.31997179 0.53493959], test_loss=[7.7442284 1.4327154], test_acc=[0.32010326 0.53343372]\n",
      "2/50: weights=[0.00734458 1.9926554 ], train_loss=[5.3692646 1.0478305], train_acc=[0.31997179 0.64025432], test_loss=[5.3678403 1.0475608], test_acc=[0.32010326 0.64264458]\n",
      "4/50: weights=[0.00212916 1.9978708 ], train_loss=[3.0135107 0.6790109], train_acc=[0.31997179 0.79456934], test_loss=[3.0128531  0.68150634], test_acc=[0.32010326 0.79416299]\n",
      "6/50: weights=[0.00862109 1.9913788 ], train_loss=[1.4992015  0.55278397], train_acc=[0.31997179 0.82638366], test_loss=[1.4995078  0.55701184], test_acc=[0.32010326 0.82345559]\n",
      "8/50: weights=[0.7245668 1.2754332], train_loss=[0.60359704 0.5033662 ], train_acc=[0.68115163 0.83705616], test_loss=[0.6038355 0.5092526], test_acc=[0.68201212 0.83288516]\n",
      "10/50: weights=[1.020173  0.9798269], train_loss=[0.5770427  0.47854325], train_acc=[0.70211418 0.84329473], test_loss=[0.5777063  0.48596805], test_acc=[0.70252053 0.83915959]\n",
      "12/50: weights=[0.67711174 1.3228883 ], train_loss=[0.5594059  0.45941916], train_acc=[0.72306479 0.84746573], test_loss=[0.56055677 0.46825376], test_acc=[0.7240687  0.84267326]\n",
      "14/50: weights=[0.6537091 1.3462908], train_loss=[0.54226935 0.44382715], train_acc=[0.73291265 0.85223429], test_loss=[0.5442823 0.4538858], test_acc=[0.73206411 0.847155  ]\n",
      "Learning rate gets updated\n",
      "16/50: weights=[0.5256425 1.4743574], train_loss=[0.52554977 0.43108067], train_acc=[0.7473259  0.85537748], test_loss=[0.5285014  0.44265038], test_acc=[0.74565272 0.8499516 ]\n",
      "18/50: weights=[0.5904685 1.4095316], train_loss=[0.51262975 0.4204222 ], train_acc=[0.75483131 0.85798286], test_loss=[0.5166954 0.4332684], test_acc=[0.75246495 0.85127819]\n",
      "20/50: weights=[0.2597453 1.7402548], train_loss=[0.49945867 0.4110848 ], train_acc=[0.76999749 0.86070776], test_loss=[0.50461537 0.42548433], test_acc=[0.76598186 0.85378796]\n",
      "22/50: weights=[0.33357683 1.6664232 ], train_loss=[0.48520875 0.40259916], train_acc=[0.77729973 0.86333704], test_loss=[0.49143538 0.41858265], test_acc=[0.77189774 0.85608261]\n",
      "24/50: weights=[0.31112388 1.6888762 ], train_loss=[0.4706375  0.39461777], train_acc=[0.78415976 0.86648023], test_loss=[0.47792038 0.41168687], test_acc=[0.77917608 0.85844896]\n",
      "Learning rate gets updated\n",
      "26/50: weights=[0.31141165 1.6885883 ], train_loss=[0.45697218 0.3878626 ], train_acc=[0.79527446 0.86842829], test_loss=[0.46527112 0.406531  ], test_acc=[0.78767344 0.85959629]\n",
      "28/50: weights=[0.49492797 1.505072  ], train_loss=[0.44531587 0.3808964 ], train_acc=[0.79957692 0.86979073], test_loss=[0.45444497 0.40122834], test_acc=[0.790972   0.85984726]\n",
      "30/50: weights=[0.3057606 1.6942393], train_loss=[0.4371078  0.37461323], train_acc=[0.8017162  0.87213319], test_loss=[0.44713572 0.39632952], test_acc=[0.7933025  0.86163996]\n",
      "32/50: weights=[0.3961805 1.6038194], train_loss=[0.4290613  0.36900327], train_acc=[0.80549281 0.87387807], test_loss=[0.43974936 0.3922172 ], test_acc=[0.79638593 0.8630024 ]\n",
      "34/50: weights=[0.49720338 1.5027965 ], train_loss=[0.42063424 0.36377415], train_acc=[0.81203017 0.87577833], test_loss=[0.43205658 0.38847053], test_acc=[0.80280377 0.86465168]\n",
      "Learning rate gets updated\n",
      "36/50: weights=[0.49944636 1.5005536 ], train_loss=[0.4154944  0.35836884], train_acc=[0.81369139 0.87706907], test_loss=[0.42750347 0.38460937], test_acc=[0.80420207 0.86522534]\n",
      "38/50: weights=[0.21184675 1.7881532 ], train_loss=[0.40994695 0.3538474 ], train_acc=[0.81696605 0.87932786], test_loss=[0.42256528 0.3812799 ], test_acc=[0.80692697 0.86730487]\n",
      "40/50: weights=[0.3649179 1.6350821], train_loss=[0.40613848 0.349516  ], train_acc=[0.81753971 0.88049909], test_loss=[0.41938958 0.37832668], test_acc=[0.80782331 0.86762755]\n",
      "42/50: weights=[0.319278  1.6807219], train_loss=[0.40102914 0.34490156], train_acc=[0.822619   0.88150299], test_loss=[0.41475582 0.37549245], test_acc=[0.81126528 0.86830877]\n",
      "44/50: weights=[0.42325285 1.5767472 ], train_loss=[0.3968438 0.3408869], train_acc=[0.82356316 0.88347496], test_loss=[0.41106087 0.37253165], test_acc=[0.81262773 0.8699222 ]\n",
      "46/50: weights=[0.28660154 1.7133985 ], train_loss=[0.39350113 0.33694404], train_acc=[0.82577414 0.88480155], test_loss=[0.40807328 0.36998734], test_acc=[0.81445628 0.87089025]\n",
      "48/50: weights=[0.35330057 1.6466995 ], train_loss=[0.39056188 0.33232063], train_acc=[0.82719635 0.88573375], test_loss=[0.40580073 0.36725244], test_acc=[0.81628482 0.87056757]\n",
      "50/50: weights=[0.35624894 1.643751  ], train_loss=[0.387442   0.32838666], train_acc=[0.830471   0.88727547], test_loss=[0.40296218 0.3644823 ], test_acc=[0.81739629 0.87153562]\n",
      "==>>> total trainning batch number: 327\n",
      "==>>> total testing batch number: 109\n",
      "Preference Vector (2/5):\n",
      "[0.9238795  0.38268343]\n",
      "fealsible solution is obtained.\n",
      "1/50: weights=[0.00634179 1.9936581 ], train_loss=[2.1800125 1.5347729], train_acc=[0.31997179 0.51446703], test_loss=[2.1790235 1.5332266], test_acc=[0.32010326 0.51647485]\n",
      "2/50: weights=[0.00718908 1.9928108 ], train_loss=[1.3770411 1.08395  ], train_acc=[0.31997179 0.63846163], test_loss=[1.3766    1.0837121], test_acc=[0.32010326 0.64221433]\n",
      "4/50: weights=[0.8138152 1.1861846], train_loss=[0.6049579 0.7019131], train_acc=[0.68455774 0.7965891 ], test_loss=[0.6035342 0.7044911], test_acc=[0.68427091 0.79455738]\n",
      "6/50: weights=[0.7631326 1.2368674], train_loss=[0.5869699  0.58313173], train_acc=[0.69960441 0.82008533], test_loss=[0.58592373 0.5864092 ], test_acc=[0.69975978 0.81728873]\n",
      "8/50: weights=[0.79881465 1.2011852 ], train_loss=[0.5742269 0.5281604], train_acc=[0.71218912 0.82989734], test_loss=[0.57370836 0.53224826], test_acc=[0.71571475 0.82739952]\n",
      "10/50: weights=[0.6782107 1.3217893], train_loss=[0.5632113  0.49391806], train_acc=[0.71492596 0.83819153], test_loss=[0.56319815 0.49925265], test_acc=[0.71779427 0.83546664]\n",
      "12/50: weights=[0.51560295 1.484397  ], train_loss=[0.54992867 0.4707806 ], train_acc=[0.72833531 0.84364132], test_loss=[0.550446  0.4775506], test_acc=[0.72944677 0.83955398]\n",
      "14/50: weights=[0.6019513 1.3980488], train_loss=[0.53820455 0.45146912], train_acc=[0.7375856  0.84937794], test_loss=[0.53933895 0.45988584], test_acc=[0.73747804 0.84518303]\n",
      "16/50: weights=[0.6122347 1.3877653], train_loss=[0.5258017 0.4366165], train_acc=[0.74942933 0.85329796], test_loss=[0.5277747  0.44685596], test_acc=[0.74801907 0.8490194 ]\n",
      "18/50: weights=[0.6145425 1.3854574], train_loss=[0.5130375 0.4242272], train_acc=[0.75609814 0.85607066], test_loss=[0.5159155  0.43600944], test_acc=[0.75454448 0.85152917]\n",
      "20/50: weights=[0.766222 1.233778], train_loss=[0.49959227 0.41346163], train_acc=[0.76679455 0.85983531], test_loss=[0.50325096 0.42692858], test_acc=[0.76250403 0.85314259]\n",
      "22/50: weights=[0.41080654 1.5891935 ], train_loss=[0.4881759 0.4037034], train_acc=[0.77769412 0.86289484], test_loss=[0.49248865 0.41909346], test_acc=[0.77254311 0.85550895]\n",
      "Learning rate gets updated\n",
      "24/50: weights=[0.21556754 1.7844325 ], train_loss=[0.4770634  0.39493686], train_acc=[0.78224756 0.86614559], test_loss=[0.48227558 0.41183296], test_acc=[0.77777778 0.85762432]\n",
      "26/50: weights=[0.35224658 1.6477535 ], train_loss=[0.46760854 0.38830245], train_acc=[0.78884467 0.86756779], test_loss=[0.47356716 0.40660137], test_acc=[0.7835144  0.85952458]\n",
      "28/50: weights=[0.530149  1.4698509], train_loss=[0.45868677 0.38098833], train_acc=[0.79216713 0.8699222 ], test_loss=[0.46532518 0.4010925 ], test_acc=[0.78613173 0.8602058 ]\n",
      "30/50: weights=[0.3775235 1.6224766], train_loss=[0.45071253 0.3751331 ], train_acc=[0.79761691 0.8717627 ], test_loss=[0.45771924 0.396529  ], test_acc=[0.79172493 0.86174752]\n",
      "32/50: weights=[0.4067992 1.5932007], train_loss=[0.444665  0.3688809], train_acc=[0.7984535  0.87354344], test_loss=[0.4521821  0.39176854], test_acc=[0.79111541 0.86246459]\n",
      "34/50: weights=[0.2934798 1.7065203], train_loss=[0.43748647 0.36335042], train_acc=[0.80264841 0.87539589], test_loss=[0.44533235 0.38759598], test_acc=[0.79513105 0.86425729]\n",
      "36/50: weights=[0.65027326 1.3497268 ], train_loss=[0.43156263 0.3580303 ], train_acc=[0.8058872  0.87734395], test_loss=[0.43979514 0.38384876], test_acc=[0.79857302 0.86547632]\n",
      "38/50: weights=[0.43057844 1.5694214 ], train_loss=[0.4262789 0.3532855], train_acc=[0.80972357 0.87931591], test_loss=[0.43498898 0.38046116], test_acc=[0.80190743 0.86630096]\n",
      "40/50: weights=[0.31126046 1.6887395 ], train_loss=[0.42140606 0.3480258 ], train_acc=[0.81291456 0.88057079], test_loss=[0.43051893 0.3766973 ], test_acc=[0.80405866 0.86687462]\n",
      "42/50: weights=[0.20427635 1.7957237 ], train_loss=[0.41678175 0.34317768], train_acc=[0.81510165 0.88219617], test_loss=[0.42659104 0.37347466], test_acc=[0.80524183 0.86916927]\n",
      "44/50: weights=[0.32761097 1.6723891 ], train_loss=[0.4123891  0.33873025], train_acc=[0.817958   0.88395301], test_loss=[0.42265505 0.37057185], test_acc=[0.80828941 0.86970707]\n",
      "46/50: weights=[0.3585969 1.6414031], train_loss=[0.40831634 0.33423835], train_acc=[0.81900972 0.88493301], test_loss=[0.41919383 0.36748567], test_acc=[0.80965186 0.87089025]\n",
      "48/50: weights=[0.33690864 1.6630915 ], train_loss=[0.4045862  0.32982045], train_acc=[0.82141192 0.88755034], test_loss=[0.41596654 0.36463198], test_acc=[0.81173138 0.87246782]\n",
      "50/50: weights=[0.07286655 1.9271334 ], train_loss=[0.4007115 0.3257672], train_acc=[0.82294169 0.88887694], test_loss=[0.4125114  0.36206222], test_acc=[0.81230504 0.87336417]\n",
      "==>>> total trainning batch number: 327\n",
      "==>>> total testing batch number: 109\n",
      "Preference Vector (3/5):\n",
      "[0.70710677 0.70710677]\n",
      "fealsible solution is obtained.\n",
      "1/50: weights=[0.02749876 1.9725012 ], train_loss=[0.8244996 1.4985404], train_acc=[0.68002821 0.53889546], test_loss=[0.8238755 1.4983355], test_acc=[0.67989674 0.54064035]\n",
      "2/50: weights=[0.64866924 1.3513308 ], train_loss=[0.6108048 1.1060606], train_acc=[0.68073333 0.62775328], test_loss=[0.6099558 1.106461 ], test_acc=[0.68165358 0.63084866]\n",
      "4/50: weights=[0.6532018 1.3467982], train_loss=[0.5851666  0.80469733], train_acc=[0.69892319 0.76650771], test_loss=[0.5852058  0.80766773], test_acc=[0.70011832 0.76433258]\n",
      "6/50: weights=[1.4472094 0.5527907], train_loss=[0.5579868  0.67892784], train_acc=[0.729638   0.79997132], test_loss=[0.5588689  0.68267494], test_acc=[0.73098849 0.79850131]\n",
      "8/50: weights=[0.8649135 1.1350865], train_loss=[0.527901  0.6002261], train_acc=[0.74638175 0.82041997], test_loss=[0.5301678 0.6046075], test_acc=[0.74583199 0.8184002 ]\n",
      "10/50: weights=[1.1304034  0.86959654], train_loss=[0.49844763 0.5500209 ], train_acc=[0.7668782  0.82748318], test_loss=[0.5025504 0.5546379], test_acc=[0.7649421  0.82524829]\n",
      "12/50: weights=[0.94572437 1.0542756 ], train_loss=[0.46980307 0.51526344], train_acc=[0.78554611 0.83539493], test_loss=[0.4755054  0.52082926], test_acc=[0.78376537 0.83134344]\n",
      "Learning rate gets updated\n",
      "14/50: weights=[0.9696024 1.0303977], train_loss=[0.44589972 0.49030843], train_acc=[0.8003179  0.83968544], test_loss=[0.4534495  0.49700665], test_acc=[0.79448568 0.83611201]\n",
      "16/50: weights=[0.8216697 1.1783303], train_loss=[0.42913073 0.47228268], train_acc=[0.80877942 0.84372498], test_loss=[0.43846118 0.47998807], test_acc=[0.80058083 0.83948227]\n",
      "18/50: weights=[1.074324 0.925676], train_loss=[0.4163286  0.45758498], train_acc=[0.8156036  0.84746573], test_loss=[0.42704725 0.46650285], test_acc=[0.80660428 0.84299595]\n",
      "20/50: weights=[0.85105103 1.1489489 ], train_loss=[0.40584788 0.4448612 ], train_acc=[0.82113705 0.85031014], test_loss=[0.41812244 0.45506093], test_acc=[0.81216163 0.84496791]\n",
      "22/50: weights=[0.8502848 1.1497152], train_loss=[0.3975885 0.4339775], train_acc=[0.82358706 0.85341747], test_loss=[0.41141444 0.44537318], test_acc=[0.81348822 0.84704743]\n",
      "24/50: weights=[0.8457914 1.1542087], train_loss=[0.38828394 0.4244731 ], train_acc=[0.83108052 0.85623797], test_loss=[0.40354568 0.43729734], test_acc=[0.81951167 0.84980818]\n",
      "26/50: weights=[0.5310195 1.4689804], train_loss=[0.3810239  0.41579092], train_acc=[0.83414005 0.85966799], test_loss=[0.3975671  0.42997396], test_acc=[0.82234413 0.85249722]\n",
      "28/50: weights=[0.7167206 1.2832794], train_loss=[0.37402603 0.4078162 ], train_acc=[0.83736689 0.86178337], test_loss=[0.39209384 0.4233178 ], test_acc=[0.82549926 0.85403894]\n",
      "Learning rate gets updated\n",
      "30/50: weights=[0.7929372 1.2070628], train_loss=[0.36993602 0.40072265], train_acc=[0.83765372 0.86394655], test_loss=[0.3894691 0.4174265], test_acc=[0.82510487 0.85579578]\n",
      "32/50: weights=[0.8952066 1.1047934], train_loss=[0.36338845 0.3943177 ], train_acc=[0.84312741 0.86518949], test_loss=[0.38369778 0.41243497], test_acc=[0.82922807 0.8574092 ]\n",
      "34/50: weights=[0.5667397 1.4332603], train_loss=[0.35842875 0.38828817], train_acc=[0.84426278 0.86755584], test_loss=[0.38020447 0.4077051 ], test_acc=[0.82969417 0.85873579]\n",
      "36/50: weights=[0.6090358 1.3909643], train_loss=[0.35404894 0.38282692], train_acc=[0.84660524 0.86847609], test_loss=[0.37675124 0.40321693], test_acc=[0.83213223 0.86052849]\n",
      "38/50: weights=[0.88383484 1.1161652 ], train_loss=[0.34952077 0.37741223], train_acc=[0.85034599 0.87056757], test_loss=[0.37330055 0.39928815], test_acc=[0.83550249 0.86146069]\n",
      "Learning rate gets updated\n",
      "40/50: weights=[0.54172117 1.4582789 ], train_loss=[0.345537   0.37249222], train_acc=[0.85188771 0.87255148], test_loss=[0.37013477 0.39519382], test_acc=[0.83668567 0.8625363 ]\n",
      "42/50: weights=[0.84544384 1.1545562 ], train_loss=[0.34322873 0.3678663 ], train_acc=[0.85143356 0.87385417], test_loss=[0.36908615 0.3919336 ], test_acc=[0.83614786 0.86343265]\n",
      "44/50: weights=[0.5379394 1.4620606], train_loss=[0.33846208 0.36389092], train_acc=[0.85567626 0.87489393], test_loss=[0.36515504 0.38926992], test_acc=[0.83933885 0.86364777]\n",
      "Learning rate gets updated\n",
      "46/50: weights=[0.7703248 1.2296752], train_loss=[0.33562276 0.35945177], train_acc=[0.85624993 0.87628028], test_loss=[0.3633808 0.3856044], test_acc=[0.83966154 0.865799  ]\n",
      "Learning rate gets updated\n",
      "48/50: weights=[0.20575476 1.7942452 ], train_loss=[0.33270413 0.35586333], train_acc=[0.85725383 0.87741565], test_loss=[0.36142012 0.382984  ], test_acc=[0.8397691  0.86622925]\n",
      "50/50: weights=[0.8714936 1.1285064], train_loss=[0.33041275 0.3524903 ], train_acc=[0.85801872 0.87821639], test_loss=[0.3600972 0.3805625], test_acc=[0.84066545 0.86687462]\n",
      "==>>> total trainning batch number: 327\n",
      "==>>> total testing batch number: 109\n",
      "Preference Vector (4/5):\n",
      "[0.38268343 0.9238795 ]\n",
      "fealsible solution is obtained.\n",
      "1/50: weights=[1.6015631  0.39843696], train_loss=[0.594634  2.1607766], train_acc=[0.68014772 0.34423291], test_loss=[0.59541225 2.1566694 ], test_acc=[0.67993259 0.34538023]\n",
      "2/50: weights=[1.6289049 0.371095 ], train_loss=[0.5645883 1.908367 ], train_acc=[0.71180668 0.40501715], test_loss=[0.5657961 1.9045695], test_acc=[0.71424474 0.40758668]\n",
      "4/50: weights=[0.8521695 1.1478305], train_loss=[0.5129947 1.4088793], train_acc=[0.75314618 0.55312944], test_loss=[0.5160213 1.4084983], test_acc=[0.75389911 0.55498189]\n",
      "6/50: weights=[1.1386964  0.86130357], train_loss=[0.47540855 1.0185065 ], train_acc=[0.78016804 0.67747063], test_loss=[0.48019907 1.019378  ], test_acc=[0.77698899 0.67857015]\n",
      "8/50: weights=[1.1175581 0.8824418], train_loss=[0.4486178 0.79143  ], train_acc=[0.79452153 0.76385453], test_loss=[0.45550492 0.79400486], test_acc=[0.79054175 0.76250403]\n",
      "Learning rate gets updated\n",
      "10/50: weights=[0.51158696 1.4884131 ], train_loss=[0.42636633 0.66838795], train_acc=[0.80839697 0.79706715], test_loss=[0.4351553 0.6726542], test_acc=[0.80337743 0.79401958]\n",
      "12/50: weights=[1.0289661 0.9710339], train_loss=[0.40645733 0.6009747 ], train_acc=[0.81972679 0.8156275 ], test_loss=[0.41749004 0.60610723], test_acc=[0.81165968 0.81309383]\n",
      "14/50: weights=[1.5327144  0.46728545], train_loss=[0.38983503 0.55762315], train_acc=[0.82952685 0.82631195], test_loss=[0.4028184 0.5632847], test_acc=[0.81987021 0.82324047]\n",
      "16/50: weights=[1.4493599 0.5506401], train_loss=[0.3769258  0.52728695], train_acc=[0.83614786 0.83351858], test_loss=[0.3917048 0.5334995], test_acc=[0.82532    0.82980173]\n",
      "18/50: weights=[0.6171983 1.3828018], train_loss=[0.3638788  0.50445616], train_acc=[0.84122716 0.83749836], test_loss=[0.38137364 0.51121587], test_acc=[0.82940734 0.83342297]\n",
      "20/50: weights=[1.4342656  0.56573445], train_loss=[0.35593945 0.4867064 ], train_acc=[0.8476689  0.84084472], test_loss=[0.3753069 0.4940152], test_acc=[0.83435517 0.8374386 ]\n",
      "22/50: weights=[1.4779556 0.5220443], train_loss=[0.34581304 0.4726136 ], train_acc=[0.84886403 0.84355766], test_loss=[0.36753872 0.48075637], test_acc=[0.83507225 0.83862178]\n",
      "24/50: weights=[0.7331054 1.2668946], train_loss=[0.33640885 0.46009773], train_acc=[0.85443333 0.84741792], test_loss=[0.36034706 0.4690146 ], test_acc=[0.83880105 0.84199204]\n",
      "26/50: weights=[1.2715391  0.72846097], train_loss=[0.32923755 0.44907612], train_acc=[0.86026556 0.85029818], test_loss=[0.35479498 0.45879462], test_acc=[0.84339034 0.84446596]\n",
      "28/50: weights=[1.1829855  0.81701446], train_loss=[0.3215105 0.4401862], train_acc=[0.8638868  0.85201917], test_loss=[0.34936035 0.45058754], test_acc=[0.84647377 0.84679646]\n",
      "30/50: weights=[1.4400554  0.55994475], train_loss=[0.3147035  0.43099305], train_acc=[0.8671973  0.85479187], test_loss=[0.34476224 0.44245642], test_acc=[0.8485533  0.84848159]\n",
      "32/50: weights=[1.4250407 0.5749591], train_loss=[0.30949682 0.4234039 ], train_acc=[0.87050781 0.85707456], test_loss=[0.34167248 0.4357013 ], test_acc=[0.84923452 0.85056111]\n",
      "34/50: weights=[1.3108763  0.68912387], train_loss=[0.30361077 0.41638577], train_acc=[0.87334027 0.85861628], test_loss=[0.33772767 0.42979282], test_acc=[0.85149331 0.85206698]\n",
      "36/50: weights=[0.8311086 1.1688914], train_loss=[0.30028248 0.4102761 ], train_acc=[0.87424856 0.86068385], test_loss=[0.33702418 0.42462394], test_acc=[0.85163673 0.85342942]\n",
      "38/50: weights=[1.1876123  0.81238776], train_loss=[0.29457086 0.4043474 ], train_acc=[0.87704516 0.86187898], test_loss=[0.33341324 0.4196532 ], test_acc=[0.85281991 0.85425406]\n",
      "40/50: weights=[0.6828238 1.3171762], train_loss=[0.28834784 0.3984172 ], train_acc=[0.88048713 0.86410192], test_loss=[0.32878223 0.41472584], test_acc=[0.85604675 0.85572407]\n",
      "42/50: weights=[1.066324   0.93367606], train_loss=[0.28353682 0.3932048 ], train_acc=[0.88425179 0.8652851 ], test_loss=[0.32607204 0.41055164], test_acc=[0.85902262 0.85733749]\n",
      "44/50: weights=[0.9469088 1.0530913], train_loss=[0.28028056 0.3882815 ], train_acc=[0.88403667 0.86669535], test_loss=[0.32496974 0.40661812], test_acc=[0.85855652 0.85758847]\n",
      "46/50: weights=[1.2503507 0.7496494], train_loss=[0.27491605 0.38326627], train_acc=[0.88831523 0.86865536], test_loss=[0.3213761  0.40283927], test_acc=[0.86189093 0.85930945]\n",
      "48/50: weights=[0.6232363 1.3767637], train_loss=[0.27156404 0.37916932], train_acc=[0.88919962 0.86975488], test_loss=[0.3194739  0.39950967], test_acc=[0.86235703 0.85948872]\n",
      "50/50: weights=[1.2876841  0.71231586], train_loss=[0.2680117 0.3745302], train_acc=[0.89150622 0.87141611], test_loss=[0.31744188 0.3958568 ], test_acc=[0.86397046 0.86081532]\n",
      "==>>> total trainning batch number: 327\n",
      "==>>> total testing batch number: 109\n",
      "Preference Vector (5/5):\n",
      "[6.123234e-17 1.000000e+00]\n",
      "fealsible solution is obtained.\n",
      "1/50: weights=[1.9753902  0.02460975], train_loss=[0.57981414 2.5952337 ], train_acc=[0.68369725 0.05485641], test_loss=[0.58105236 2.5943801 ], test_acc=[0.68333871 0.05403177]\n",
      "2/50: weights=[1.780113   0.21988702], train_loss=[0.52627283 2.2331414 ], train_acc=[0.73696413 0.34423291], test_loss=[0.52902395 2.2288413 ], test_acc=[0.73604389 0.34538023]\n",
      "4/50: weights=[1.5931922  0.40680766], train_loss=[0.45673093 1.8583884 ], train_acc=[0.78846223 0.41878503], test_loss=[0.4631235 1.8541435], test_acc=[0.78548636 0.42225091]\n",
      "6/50: weights=[1.4108491  0.58915085], train_loss=[0.41891336 1.4851185 ], train_acc=[0.81223334 0.52831857], test_loss=[0.42833376 1.4837217 ], test_acc=[0.80416622 0.5290237 ]\n",
      "8/50: weights=[1.4769049  0.52309525], train_loss=[0.39396647 1.1914041 ], train_acc=[0.82413682 0.59780335], test_loss=[0.40665492 1.1907533 ], test_acc=[0.81657165 0.60048044]\n",
      "10/50: weights=[1.3787308  0.62126935], train_loss=[0.37750974 0.9562544 ], train_acc=[0.83376956 0.70143296], test_loss=[0.3928386  0.95693856], test_acc=[0.82610878 0.70062027]\n",
      "12/50: weights=[1.2389616  0.76103824], train_loss=[0.36419785 0.7902259 ], train_acc=[0.84002008 0.76674674], test_loss=[0.3819207 0.7928769], test_acc=[0.82983758 0.76286257]\n",
      "14/50: weights=[0.8446384 1.1553617], train_loss=[0.3535373 0.677224 ], train_acc=[0.84880427 0.79808301], test_loss=[0.37356964 0.6816196 ], test_acc=[0.83765372 0.79201176]\n",
      "16/50: weights=[1.127146  0.8728539], train_loss=[0.3416318  0.60528886], train_acc=[0.85309479 0.81603385], test_loss=[0.36438632 0.61081994], test_acc=[0.84123911 0.81079918]\n",
      "18/50: weights=[1.2125711 0.7874288], train_loss=[0.33236873 0.55949485], train_acc=[0.85745701 0.82422048], test_loss=[0.3573987  0.56571543], test_acc=[0.8444301  0.81893801]\n",
      "20/50: weights=[0.9923706 1.0076294], train_loss=[0.3242152 0.52714  ], train_acc=[0.86196264 0.83053076], test_loss=[0.35168672 0.53413165], test_acc=[0.84647377 0.82481804]\n",
      "22/50: weights=[1.1357355 0.8642644], train_loss=[0.31691802 0.50374043], train_acc=[0.86596632 0.83507225], test_loss=[0.34691232 0.51155573], test_acc=[0.84912696 0.82861855]\n",
      "24/50: weights=[1.0479066 0.9520935], train_loss=[0.31009048 0.4855    ], train_acc=[0.8695039  0.83994837], test_loss=[0.34242937 0.49415436], test_acc=[0.85127819 0.83338711]\n",
      "26/50: weights=[1.0965161  0.90348387], train_loss=[0.30379173 0.47008443], train_acc=[0.87171489 0.84441815], test_loss=[0.33856446 0.47949132], test_acc=[0.85246137 0.83715177]\n",
      "28/50: weights=[0.9626141 1.0373858], train_loss=[0.29866523 0.45738053], train_acc=[0.87699736 0.84648572], test_loss=[0.33531755 0.46771097], test_acc=[0.85536553 0.83933885]\n",
      "30/50: weights=[1.1672459 0.832754 ], train_loss=[0.29349023 0.4463797 ], train_acc=[0.87663882 0.84989184], test_loss=[0.33325446 0.4577332 ], test_acc=[0.85558065 0.84292424]\n",
      "32/50: weights=[0.9596669 1.0403332], train_loss=[0.28605223 0.43670666], train_acc=[0.88272203 0.85364454], test_loss=[0.3276568  0.44905776], test_acc=[0.85873579 0.84590011]\n",
      "34/50: weights=[0.8963311 1.1036689], train_loss=[0.28760764 0.42824993], train_acc=[0.88327178 0.8560109 ], test_loss=[0.33089584 0.4417021 ], test_acc=[0.85844896 0.84751353]\n",
      "36/50: weights=[0.7568031 1.2431967], train_loss=[0.27650863 0.42016697], train_acc=[0.88857816 0.85813823], test_loss=[0.32212633 0.4346587 ], test_acc=[0.86214191 0.84966477]\n",
      "38/50: weights=[1.0158851 0.9841148], train_loss=[0.27199352 0.41318563], train_acc=[0.88921157 0.86040897], test_loss=[0.32028893 0.42858756], test_acc=[0.86192679 0.8513499 ]\n",
      "40/50: weights=[1.1058105 0.8941894], train_loss=[0.26734054 0.406176  ], train_acc=[0.89114768 0.8620224 ], test_loss=[0.31806508 0.42257828], test_acc=[0.86350436 0.85325015]\n",
      "42/50: weights=[0.9751747 1.0248251], train_loss=[0.26738918 0.4006753 ], train_acc=[0.88931914 0.86414973], test_loss=[0.3208288 0.4177155], test_acc=[0.86099459 0.85407479]\n",
      "44/50: weights=[0.5807939 1.419206 ], train_loss=[0.26251137 0.39468116], train_acc=[0.89265354 0.86569144], test_loss=[0.31737712 0.4127584 ], test_acc=[0.86293069 0.85586748]\n",
      "Learning rate gets updated\n",
      "46/50: weights=[0.90391713 1.0960829 ], train_loss=[0.254237 0.389361], train_acc=[0.89871285 0.86706584], test_loss=[0.31102628 0.40839818], test_acc=[0.86705389 0.85701481]\n",
      "48/50: weights=[1.0564511 0.943549 ], train_loss=[0.25084502 0.38463953], train_acc=[0.90265677 0.86930073], test_loss=[0.3092236  0.40466708], test_acc=[0.86949195 0.85830555]\n",
      "50/50: weights=[0.5751117 1.4248884], train_loss=[0.24920842 0.37990257], train_acc=[0.9001709 0.8703883], test_loss=[0.3095109  0.40078628], test_acc=[0.8671973  0.85991897]\n"
     ]
    }
   ],
   "source": [
    "task_train_losses_pref, train_accs_pref, task_test_losses_pref, test_accs_pref, learning_rate_pref = run(dataset = 'mnist', base_model = 'lenet', niter = 50, npref = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea42ad0",
   "metadata": {
    "papermill": {
     "duration": 0.024069,
     "end_time": "2023-06-26T02:40:36.903995",
     "exception": false,
     "start_time": "2023-06-26T02:40:36.879926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a72d821",
   "metadata": {
    "papermill": {
     "duration": 0.023903,
     "end_time": "2023-06-26T02:40:36.951764",
     "exception": false,
     "start_time": "2023-06-26T02:40:36.927861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 33994.422369,
   "end_time": "2023-06-26T02:40:40.502613",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-06-25T17:14:06.080244",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
