{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zqkKKsVrpm3"
      },
      "source": [
        "#Ví dụ 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CFV_NJ46Vn7F"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class MinNormSolver:\n",
        "    MAX_ITER = 250\n",
        "    STOP_CRIT = 1e-6\n",
        "\n",
        "    def _min_norm_element_from2(v1v1, v1v2, v2v2):\n",
        "        \"\"\"\n",
        "        Analytical solution for min_{c} |cx_1 + (1-c)x_2|_2^2\n",
        "        d is the distance (objective) optimzed\n",
        "        v1v1 = <x1,x1>\n",
        "        v1v2 = <x1,x2>\n",
        "        v2v2 = <x2,x2>\n",
        "        \"\"\"\n",
        "        if v1v2 >= v1v1:\n",
        "            # Case: Fig 1, third column\n",
        "            gamma = 0.999\n",
        "            cost = v1v1\n",
        "            return gamma, cost\n",
        "        if v1v2 >= v2v2:\n",
        "            # Case: Fig 1, first column\n",
        "            gamma = 0.001\n",
        "            cost = v2v2\n",
        "            return gamma, cost\n",
        "        # Case: Fig 1, second column\n",
        "        gamma = -1.0 * ( (v1v2 - v2v2) / (v1v1+v2v2 - 2*v1v2) )\n",
        "        cost = v2v2 + gamma*(v1v2 - v2v2)\n",
        "        return gamma, cost\n",
        "\n",
        "    def _min_norm_2d(vecs, dps):\n",
        "        \"\"\"\n",
        "        Find the minimum norm solution as combination of two points\n",
        "        This solution is correct if vectors(gradients) lie in 2D\n",
        "        ie. min_c |\\sum c_i x_i|_2^2 st. \\sum c_i = 1 , 1 >= c_1 >= 0 for all i, c_i + c_j = 1.0 for some i, j\n",
        "        \"\"\"\n",
        "        dmin = 1e8\n",
        "        for i in range(len(vecs)):\n",
        "            for j in range(i+1,len(vecs)):\n",
        "                if (i,j) not in dps:\n",
        "                    dps[(i, j)] = 0.0\n",
        "                    dps[(i,j)] = np.dot(vecs[i], vecs[j])\n",
        "                    dps[(j, i)] = dps[(i, j)]\n",
        "                if (i,i) not in dps:\n",
        "                    dps[(i, i)] = 0.0\n",
        "                    dps[(i,i)] = np.dot(vecs[i], vecs[i])\n",
        "                if (j,j) not in dps:\n",
        "                    dps[(j, j)] = 0.0\n",
        "                    dps[(j, j)] = np.dot(vecs[j], vecs[j])\n",
        "                c,d = MinNormSolver._min_norm_element_from2(dps[(i,i)], dps[(i,j)], dps[(j,j)])\n",
        "                if d < dmin:\n",
        "                    dmin = d\n",
        "                    sol = [(i,j),c,d]\n",
        "        return sol, dps\n",
        "\n",
        "    def _projection2simplex(y):\n",
        "        \"\"\"\n",
        "        Given y, it solves argmin_z |y-z|_2 st \\sum z = 1 , 1 >= z_i >= 0 for all i\n",
        "        \"\"\"\n",
        "        m = len(y)\n",
        "        sorted_y = np.flip(np.sort(y), axis=0)\n",
        "        tmpsum = 0.0\n",
        "        tmax_f = (np.sum(y) - 1.0)/m\n",
        "        for i in range(m-1):\n",
        "            tmpsum+= sorted_y[i]\n",
        "            tmax = (tmpsum - 1)/ (i+1.0)\n",
        "            if tmax > sorted_y[i+1]:\n",
        "                tmax_f = tmax\n",
        "                break\n",
        "        return np.maximum(y - tmax_f, np.zeros(y.shape))\n",
        "\n",
        "    def _next_point(cur_val, grad, n):\n",
        "        proj_grad = grad - ( np.sum(grad) / n )\n",
        "        tm1 = -1.0*cur_val[proj_grad<0]/proj_grad[proj_grad<0]\n",
        "        tm2 = (1.0 - cur_val[proj_grad>0])/(proj_grad[proj_grad>0])\n",
        "\n",
        "        skippers = np.sum(tm1<1e-7) + np.sum(tm2<1e-7)\n",
        "        t = 1\n",
        "        if len(tm1[tm1>1e-7]) > 0:\n",
        "            t = np.min(tm1[tm1>1e-7])\n",
        "        if len(tm2[tm2>1e-7]) > 0:\n",
        "            t = min(t, np.min(tm2[tm2>1e-7]))\n",
        "\n",
        "        next_point = proj_grad*t + cur_val\n",
        "        next_point = MinNormSolver._projection2simplex(next_point)\n",
        "        return next_point\n",
        "\n",
        "    def find_min_norm_element(vecs):\n",
        "        \"\"\"\n",
        "        Given a list of vectors (vecs), this method finds the minimum norm element in the convex hull\n",
        "        as min |u|_2 st. u = \\sum c_i vecs[i] and \\sum c_i = 1.\n",
        "        It is quite geometric, and the main idea is the fact that if d_{ij} = min |u|_2 st u = c x_i + (1-c) x_j; the solution lies in (0, d_{i,j})\n",
        "        Hence, we find the best 2-task solution, and then run the projected gradient descent until convergence\n",
        "        \"\"\"\n",
        "        # Solution lying at the combination of two points\n",
        "        dps = {}\n",
        "        init_sol, dps = MinNormSolver._min_norm_2d(vecs, dps)\n",
        "\n",
        "        n=len(vecs)\n",
        "        sol_vec = np.zeros(n)\n",
        "        sol_vec[init_sol[0][0]] = init_sol[1]\n",
        "        sol_vec[init_sol[0][1]] = 1 - init_sol[1]\n",
        "\n",
        "        if n < 3:\n",
        "            # This is optimal for n=2, so return the solution\n",
        "            return sol_vec , init_sol[2]\n",
        "\n",
        "        iter_count = 0\n",
        "\n",
        "        grad_mat = np.zeros((n,n))\n",
        "        for i in range(n):\n",
        "            for j in range(n):\n",
        "                grad_mat[i,j] = dps[(i, j)]\n",
        "\n",
        "        while iter_count < MinNormSolver.MAX_ITER:\n",
        "            grad_dir = -1.0*np.dot(grad_mat, sol_vec)\n",
        "            new_point = MinNormSolver._next_point(sol_vec, grad_dir, n)\n",
        "            # Re-compute the inner products for line search\n",
        "            v1v1 = 0.0\n",
        "            v1v2 = 0.0\n",
        "            v2v2 = 0.0\n",
        "            for i in range(n):\n",
        "                for j in range(n):\n",
        "                    v1v1 += sol_vec[i]*sol_vec[j]*dps[(i,j)]\n",
        "                    v1v2 += sol_vec[i]*new_point[j]*dps[(i,j)]\n",
        "                    v2v2 += new_point[i]*new_point[j]*dps[(i,j)]\n",
        "            nc, nd = MinNormSolver._min_norm_element_from2(v1v1, v1v2, v2v2)\n",
        "            new_sol_vec = nc*sol_vec + (1-nc)*new_point\n",
        "            change = new_sol_vec - sol_vec\n",
        "            if np.sum(np.abs(change)) < MinNormSolver.STOP_CRIT:\n",
        "                return sol_vec, nd\n",
        "            sol_vec = new_sol_vec\n",
        "        return sol_vec, nd\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykRtWXgnruwF"
      },
      "source": [
        "#Ví dụ 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Rw-X7JuWrwgR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from autograd import grad\n",
        "import autograd.numpy as np\n",
        "from numpy import linalg as LA\n",
        "from scipy.linalg import norm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.optimize import minimize\n",
        "from scipy.optimize import Bounds,BFGS\n",
        "\n",
        "def f1(x):\n",
        "    return (x[0]**2+x[1]**2)/50\n",
        "def f2(x):\n",
        "    return ((x[0]-5)**2+(x[1]-5)**2)/50\n",
        "\n",
        "b = (0.0, 5.0)\n",
        "def g1(x):\n",
        "    return x[0]-5\n",
        "def g2(x):\n",
        "    return x[1]-5\n",
        "def g3(x):\n",
        "    return x[0]\n",
        "def g4(x):\n",
        "    return x[0]\n",
        "\n",
        "bound = (b, b)\n",
        "f1_dx =grad(f1)\n",
        "f2_dx =grad(f2)\n",
        "g1_df =grad(g1)\n",
        "g2_df =grad(g2)\n",
        "g3_df =grad(g3)\n",
        "g4_df =grad(g4)\n",
        "\n",
        "def rosen(x,y):\n",
        "    \"\"\"The Rosenbrock function\"\"\"\n",
        "    return np.sqrt(np.sum((x-y)**2))\n",
        "def find_min(y,n):\n",
        "    x = np.random.rand(1,n).tolist()[0]\n",
        "    res = minimize(rosen, x, args=(y), jac=\"2-point\",bounds= bound, method='SLSQP', options={'disp': False})\n",
        "    return res.x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "58RP0HxwsqEw"
      },
      "outputs": [],
      "source": [
        "def concave_fun_eval(x):\n",
        "    \"\"\"\n",
        "    return the function values and gradient values\n",
        "    \"\"\"\n",
        "    return np.stack([f1(x), f2(x)]), np.stack([f1_dx(x), f2_dx(x)])\n",
        "\n",
        "\n",
        "def create_pf6():\n",
        "    # example 2\n",
        "    ps = np.linspace(0,5,num = 1000)\n",
        "    pf = []\n",
        "    for x1 in ps:\n",
        "        x = np.array([x1,x1])\n",
        "        f,_ = concave_fun_eval(x)\n",
        "        pf.append(f)\n",
        "    pf = np.array(pf)\n",
        "    return pf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "HnQhZqCAtd1k"
      },
      "outputs": [],
      "source": [
        "import autograd.numpy as np\n",
        "from autograd import grad\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# use autograd to calculate the gradient\n",
        "import autograd.numpy as np\n",
        "from autograd import grad\n",
        "from scipy.linalg import norm\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def get_d_paretomtl(grads,value, constraint,weights,i):\n",
        "    # calculate the gradient direction for Pareto MTL\n",
        "    nobj, dim = grads.shape\n",
        "\n",
        "    # check active constraints\n",
        "    normalized_current_weight = weights[i]/np.linalg.norm(weights[i])\n",
        "    normalized_rest_weights = np.delete(weights, (i), axis=0) / np.linalg.norm(np.delete(weights, (i), axis=0), axis = 1,keepdims = True)\n",
        "    w = normalized_rest_weights - normalized_current_weight\n",
        "\n",
        "    # solve QP\n",
        "    gx =  np.dot(w,value/np.linalg.norm(value))\n",
        "    idx = gx >  0\n",
        "\n",
        "    test = np.concatenate((grads, np.dot(w[idx],grads)), axis = 0)\n",
        "\n",
        "    if test.ndim == constraint.ndim:\n",
        "      vec =  np.concatenate((test, constraint), axis = 0)\n",
        "    else:\n",
        "      vec = test\n",
        "\n",
        "    vec = vec/norm(vec)\n",
        "\n",
        "    # use MinNormSolver to solve QP\n",
        "    sol, nd = MinNormSolver.find_min_norm_element(vec)\n",
        "\n",
        "    # reformulate ParetoMTL as linear scalarization method, return the weights\n",
        "    weight0 =  sol[0] + np.sum(np.array([sol[j] * w[idx][j - 2,0] for j in np.arange(2,2 + np.sum(idx))]))\n",
        "    weight1 = sol[1] + np.sum(np.array([sol[j] * w[idx][j - 2,1] for j in np.arange(2,2 + np.sum(idx))]))\n",
        "\n",
        "    num_cons = len(constraint)\n",
        "    if num_cons != 0:\n",
        "      weight_cons = sol[-num_cons:]\n",
        "      weight = np.array([weight0] + [weight1] + weight_cons.tolist())\n",
        "    else:\n",
        "      weight = np.stack([weight0, weight1])\n",
        "    return weight\n",
        "\n",
        "\n",
        "def get_d_paretomtl_init(grads,value,constraint, weights,i):\n",
        "    # calculate the gradient direction for Pareto MTL initialization\n",
        "    nobj, dim = grads.shape\n",
        "\n",
        "    # check active constraints\n",
        "    normalized_current_weight = weights[i]/np.linalg.norm(weights[i])\n",
        "    normalized_rest_weights = np.delete(weights, (i), axis=0) / np.linalg.norm(np.delete(weights, (i), axis=0), axis = 1,keepdims = True)\n",
        "    w = normalized_rest_weights - normalized_current_weight\n",
        "\n",
        "    gx =  np.dot(w,value/np.linalg.norm(value))\n",
        "    idx = gx >  0\n",
        "\n",
        "    if np.sum(idx) <= 0:\n",
        "        return np.zeros(nobj)\n",
        "    if np.sum(idx) == 1:\n",
        "        sol = np.ones(1)\n",
        "    else:\n",
        "        test = np.dot(w[idx],grads)\n",
        "        if constraint.ndim == test.ndim:\n",
        "          vec =  np.concatenate((test, constraint), axis = 0)\n",
        "        else:\n",
        "          vec = test\n",
        "        vec = vec/norm(vec)\n",
        "\n",
        "        sol, nd = MinNormSolver.find_min_norm_element(vec)\n",
        "\n",
        "    # calculate the weights\n",
        "    weight0 =  np.sum(np.array([sol[j] * w[idx][j ,0] for j in np.arange(0, np.sum(idx))]))\n",
        "    weight1 =  np.sum(np.array([sol[j] * w[idx][j ,1] for j in np.arange(0, np.sum(idx))]))\n",
        "\n",
        "    num_cons = len(constraint)\n",
        "    if num_cons != 0:\n",
        "      weight_cons = sol[-num_cons:]\n",
        "      weight = np.array([weight0] + [weight1] + weight_cons.tolist())\n",
        "    else:\n",
        "      weight = np.stack([weight0, weight1])\n",
        "    return weight\n",
        "\n",
        "def concave_fun_eval(x):\n",
        "    \"\"\"\n",
        "    return the function values and gradient values\n",
        "    \"\"\"\n",
        "    return np.stack([f1(x), f2(x)]), np.stack([f1_dx(x), f2_dx(x)])\n",
        "\n",
        "\n",
        "def circle_points(r, n):\n",
        "    # generate evenly distributed preference vector\n",
        "    circles = []\n",
        "    for r, n in zip(r, n):\n",
        "        t = np.linspace(0, 0.5 * np.pi, n)\n",
        "        x = r * np.cos(t)\n",
        "        y = r * np.sin(t)\n",
        "        circles.append(np.c_[x, y])\n",
        "    return circles\n",
        "\n",
        "def circle_points2(K, min_angle=None, max_angle=None):\n",
        "    # generate evenly distributed preference vector\n",
        "    ang0 = np.pi / 30. if min_angle is None else min_angle\n",
        "    ang1 = np.pi * 8 / 20. if max_angle is None else max_angle\n",
        "    angles = np.linspace(ang0, ang1, K, endpoint=True)\n",
        "    x = np.cos(angles)\n",
        "    y = np.sin(angles)\n",
        "    return np.c_[x, y]\n",
        "\n",
        "\n",
        "# calculate the gradients using autograd\n",
        "f1_dx = grad(f1)\n",
        "f2_dx = grad(f2)\n",
        "\n",
        "\n",
        "def pareto_mtl_search(ref_vecs,i, t_iter = 1000, n_dim = 2, step_size = 2, sigma = 1, kappa = 0.95, eps = 0.001, count_check = 10):\n",
        "    \"\"\"\n",
        "    Pareto MTL\n",
        "    \"\"\"\n",
        "\n",
        "    # randomly generate one solution\n",
        "    x = np.random.uniform(0, 1, n_dim)\n",
        "    x = find_min(x, 2)\n",
        "    f_all = []\n",
        "    x_all = []\n",
        "    df_all = []\n",
        "\n",
        "    # find the initial solution\n",
        "    for t in range(int(t_iter * 0.2)):\n",
        "        f, f_dx = concave_fun_eval(x)\n",
        "        # f, f_dx = convex_fun_eval(x)\n",
        "        constraint = []\n",
        "        value_set = [[g1(x),g1_df(x)], [g2(x),g2_df(x)], [g3(x), g3_df(x)], [g4(x), g4_df(x)]]\n",
        "\n",
        "        for g_value in value_set:\n",
        "          if g_value[0]<=eps and g_value[0]>=-eps:\n",
        "            constraint.append(g_value[1])\n",
        "        constraint = np.array(constraint)\n",
        "        weights =  get_d_paretomtl_init(f_dx, f, constraint, ref_vecs,i)\n",
        "\n",
        "        if len(weights) > len(f_dx):\n",
        "          direction_descent = -np.dot(weights[0:len(f_dx)].T,f_dx) - np.dot(weights[len(f_dx):].T, constraint)\n",
        "        else:\n",
        "          direction_descent = -np.dot(weights.T,f_dx)\n",
        "\n",
        "        x = x + step_size * direction_descent\n",
        "        x = find_min(x, 2)\n",
        "        x_all.append(x)\n",
        "\n",
        "    count = 0\n",
        "    # find the Pareto optimal solution\n",
        "    for t in range(int(t_iter * 0.8)):\n",
        "        #f, f_dx = convex_fun_eval(x)\n",
        "        f, f_dx = concave_fun_eval(x)\n",
        "        f_all.append(f)\n",
        "        df_all.append(f_dx)\n",
        "        constraint = []\n",
        "        value_set = [[g1(x),g1_df(x)], [g2(x),g2_df(x)], [g3(x),g3_df(x)], [g4(x),g4_df(x)]]\n",
        "\n",
        "        for g_value in value_set:\n",
        "          if g_value[0]<=eps and g_value[0]>=-eps:\n",
        "            constraint.append(g_value[1])\n",
        "        constraint = np.array(constraint)\n",
        "\n",
        "        weights =  get_d_paretomtl(f_dx, f, constraint, ref_vecs, i)\n",
        "\n",
        "        if len(weights) > len(f_dx):\n",
        "          direction_descent = -np.dot(weights[0:len(f_dx)].T,f_dx) - np.dot(weights[len(f_dx):].T, constraint)\n",
        "          x_next = x + step_size * direction_descent  #x_k+1 = x_k + alpha*s_k\n",
        "          #x_next = find_min(x_next, n_dim)\n",
        "          f_after, f_dx_after = concave_fun_eval(x_next)\n",
        "          #f_after, f_dx_after = convex_fun_eval(x_next)\n",
        "\n",
        "          if np.all(f_after <= f + sigma*np.dot(f_dx, step_size * direction_descent)):\n",
        "            step_size *= 1\n",
        "          else:\n",
        "            step_size *= kappa\n",
        "        else:\n",
        "          direction_descent = -np.dot(weights.T,f_dx)\n",
        "          x_next = x + step_size * direction_descent  #x_k+1 = x_k + alpha*s_k\n",
        "          #x_next = find_min(x_next, n_dim)\n",
        "          f_after, f_dx_after = concave_fun_eval(x_next)\n",
        "          #f_after, f_dx_after = convex_fun_eval(x_next)\n",
        "\n",
        "          if np.all(f_after <= f + sigma*np.dot(f_dx, step_size * direction_descent)):\n",
        "            step_size *= 1\n",
        "          else:\n",
        "            step_size *= kappa\n",
        "\n",
        "        if -1/2*norm(direction_descent)**2 >= -eps or -1/2*norm(direction_descent)**2 <= eps:\n",
        "          break\n",
        "\n",
        "        x = x + step_size * direction_descent\n",
        "        #x = find_min(x, n_dim)\n",
        "        x_all.append(x)\n",
        "\n",
        "    return x, f, x_all, f_all, df_all\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "_F3gXY4AsuAz",
        "outputId": "e8c0f0d4-fc72-4c9f-dbf6-c0ca1ce0230c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0\n",
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "pf = create_pf6()\n",
        "f_value_list = []\n",
        "x_value_list = []\n",
        "num = 10\n",
        "\n",
        "weights = circle_points([1], [num])[0]\n",
        "\n",
        "for i in range(num):\n",
        "\n",
        "    print(i)\n",
        "\n",
        "    x, f, x_all, f_all, df_all = pareto_mtl_search(ref_vecs = weights,i = i)\n",
        "\n",
        "    f_value_list.append(f)\n",
        "    x_value_list.append(x)\n",
        "\n",
        "f_value = np.array(f_value_list)\n",
        "plt.plot(pf[:,0],pf[:,1])\n",
        "plt.xlabel(\"f1\")\n",
        "plt.ylabel(\"f2\")\n",
        "plt.scatter(f_value[:,0], f_value[:,1], c = 'r', s = 80)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "7zqkKKsVrpm3",
        "ykRtWXgnruwF"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
